{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LLM: Zero-shot classification through LLMs and prompts",
   "id": "dd0560725aae3b41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Models**:\n",
    "\n",
    "- GPT-4o (OpenAI)\n",
    "- Gemini (Google)\n",
    "- Gemma (Google)\n",
    "- Llama (Meta)\n",
    "- Claude (Anthropic)\n",
    "- DeepSeek\n"
   ],
   "id": "d7a620a322cdfbae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0 Imports",
   "id": "cc42939b0f2e6112"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:56:38.839866Z",
     "start_time": "2025-05-16T09:56:38.825005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import pdist"
   ],
   "id": "2aaae4e734b1e3c4",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:01:58.971242Z",
     "start_time": "2025-05-16T10:01:58.911271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test_simple_prompt_df = pd.read_csv(\"../dat/prompts/X_test_simple_prompt.csv\", sep = \",\", index_col = 0)\n",
    "\n",
    "X_test_class_definitions_prompt_df = pd.read_csv(\"../dat/prompts/X_test_class_definitions_prompt.csv\", sep = \",\", index_col = 0)\n",
    "\n",
    "X_test_profiled_simple_prompt_df = pd.read_csv(\"../dat/prompts/X_test_profiled_simple_prompt.csv\", sep = \",\", index_col = 0)\n",
    "\n",
    "X_test_few_shot_prompt_df = pd.read_csv(\"../dat/prompts/X_test_few_shot_prompt.csv\", sep = \",\", index_col = 0)\n",
    "\n",
    "X_test_vignette_prompt_df = pd.read_csv(\"../dat/prompts/X_test_vignette_prompt.csv\", sep = \",\", index_col = 0)"
   ],
   "id": "6f52bfed5f097045",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:03:07.092653Z",
     "start_time": "2025-05-16T10:03:07.088184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert to arrays\n",
    "X_test_simple_prompt = X_test_simple_prompt_df.values.flatten()\n",
    "X_test_class_definitions_prompt = X_test_class_definitions_prompt_df.values.flatten()\n",
    "X_test_profiled_simple_prompt = X_test_profiled_simple_prompt_df.values.flatten()\n",
    "X_test_few_shot_prompt = X_test_few_shot_prompt_df.values.flatten()\n",
    "X_test_vignette_prompt = X_test_vignette_prompt_df.values.flatten()"
   ],
   "id": "817be744e50093b5",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b5e409ae0b81dc9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Zero-shot classification with LLMs",
   "id": "73ae6d6f42430acd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this section, I will use the prompts created in the previous section to **classify the test set using different LLMs**. The LLMs will be used to classify whether a person develops a psychological disorder between time point T1 and T2.",
   "id": "e7c46aa0e2c9031f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 ChatGPT-4o (OpenAI)",
   "id": "7c184484efa02be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1.1 Testing prompting",
   "id": "b3181ef2a9c5ad83"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-16T08:44:53.170871Z",
     "start_time": "2025-05-16T08:44:53.166891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # testing\n",
    "# response = client.responses.create(\n",
    "#     model = \"gpt-4o-mini\",\n",
    "#     instructions = \"You are a coding assistant that talks like a pirate.\",\n",
    "#     input = \"How do I check if a Python object is an instance of a class?\",\n",
    "# )\n",
    "#\n",
    "# print(response.output_text)"
   ],
   "id": "738fb998b35415c6",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f96758305e52ce67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1.2. Prompting with ChatGPT-4o",
   "id": "34bf1926b6e19c7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:44:53.425607Z",
     "start_time": "2025-05-16T08:44:53.419843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# simple_prompt_array_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_simple_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = simple_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     simple_prompt_array_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_simple_prompt = end - start\n",
    "# time_GPT_simple_prompt_df = pd.DataFrame({\"time\": [time_GPT_simple_prompt]})\n",
    "# time_GPT_simple_prompt_df.to_csv(\"../exp/times_LLMs/time_GPT4_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_simple_GPT = pd.Series(simple_prompt_array_GPT).value_counts()\n",
    "# print(counts_simple_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# simple_prompt_array_GPT = [1 if response == \"YES\" else 0 if response == \"NO\" else np.nan for response in simple_prompt_array_GPT]\n",
    "# simple_prompt_array_GPT\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# simple_prompt_df_GPT = pd.DataFrame(simple_prompt_array_GPT, columns = [\"y_pred\"])\n",
    "# simple_prompt_df_GPT.to_csv(\"../exp/preds_LLMs/y_pred_GPT4_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "bff465ba605628f4",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:44:53.503877Z",
     "start_time": "2025-05-16T08:44:53.496064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class_def_array_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_class_definitions_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = class_definitions_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     class_def_array_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_class_definitions = end - start\n",
    "# time_GPT_class_definitions_df = pd.DataFrame({\"time\": [time_GPT_class_definitions]})\n",
    "# time_GPT_class_definitions_df.to_csv(\"../exp/times_LLMs/time_GPT4_class_definitions_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_class_def_GPT = pd.Series(class_def_array_GPT).value_counts()\n",
    "# print(counts_class_def_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# class_def_array_GPT = [1 if response == \"YES\" else 0 for response in class_def_array_GPT]\n",
    "# class_def_array_GPT\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# class_def_df_GPT = pd.DataFrame(class_def_array_GPT, columns = [\"y_pred\"])\n",
    "# class_def_df_GPT.to_csv(\"../exp/preds_LLMs/y_pred_GPT4_class_definitions_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "63f70e77e37a9919",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:44:53.570956Z",
     "start_time": "2025-05-16T08:44:53.563374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# profiled_simple_array_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_profiled_simple_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = profiled_simple_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     profiled_simple_array_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_profiled_simple = end - start\n",
    "# time_GPT_profiled_simple_df = pd.DataFrame({\"time\": [time_GPT_profiled_simple]})\n",
    "# time_GPT_profiled_simple_df.to_csv(\"../exp/times_LLMs/time_GPT4_profiled_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_profiled_simple_GPT = pd.Series(profiled_simple_array_GPT).value_counts()\n",
    "# print(counts_profiled_simple_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# profiled_simple_array_GPT_val = [1 if response == \"YES\" else 0 for response in profiled_simple_array_GPT]\n",
    "# profiled_simple_array_GPT_val\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# profiled_simple_df_GPT = pd.DataFrame(profiled_simple_array_GPT_val, columns = [\"y_pred\"])\n",
    "# profiled_simple_df_GPT.to_csv(\"../exp/preds_LLMs/y_pred_GPT4_profiled_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "8fff5eef0784f0bf",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:44:53.712353Z",
     "start_time": "2025-05-16T08:44:53.708808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# few_shot_array_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_few_shot_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = few_shot_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     few_shot_array_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_few_shot = end - start\n",
    "# time_GPT_few_shot_df = pd.DataFrame({\"time\": [time_GPT_few_shot]})\n",
    "# time_GPT_few_shot_df.to_csv(\"../exp/times_LLMs/time_GPT4_few_shot_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_few_shot_GPT = pd.Series(few_shot_array_GPT).value_counts()\n",
    "# print(counts_few_shot_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# few_shot_array_GPT_val = [1 if response == \"YES\" else 0 for response in few_shot_array_GPT]\n",
    "# few_shot_array_GPT_val\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# few_shot_df_GPT = pd.DataFrame(few_shot_array_GPT_val, columns = [\"y_pred\"])\n",
    "# few_shot_df_GPT.to_csv(\"../exp/preds_LLMs/y_pred_GPT4_few_shot_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "f7389ea105f9761b",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:44:53.769947Z",
     "start_time": "2025-05-16T08:44:53.766408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# vignette_array_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_vignette_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = vignette_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     vignette_array_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_vignette = end - start\n",
    "# time_GPT_vignette_df = pd.DataFrame({\"time\": [time_GPT_vignette]})\n",
    "# time_GPT_vignette_df.to_csv(\"../exp/times_LLMs/time_GPT4_vignette_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_vignette_GPT = pd.Series(vignette_array_GPT).value_counts()\n",
    "# print(counts_vignette_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# vignette_array_GPT_val = [1 if response == \"YES\" else 0 for response in vignette_array_GPT]\n",
    "# vignette_array_GPT_val\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# vignette_df_GPT = pd.DataFrame(vignette_array_GPT_val, columns = [\"y_pred\"])\n",
    "# vignette_df_GPT.to_csv(\"../exp/preds_LLMs/y_pred_GPT4_vignette_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "11d6cfb1d391ec89",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1.3 Misclassified cases reasons",
   "id": "1af0af9d4db4cb1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:31:42.279213Z",
     "start_time": "2025-05-16T09:31:42.261533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred_GPT4_simple_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_simple_prompt.csv\", sep = \",\")\n",
    "y_pred_GPT4_class_definition_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_class_definitions_prompt.csv\", sep = \",\")\n",
    "y_pred_GPT4_profiled_simple_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_profiled_simple_prompt.csv\", sep = \",\")\n",
    "y_pred_GPT4_few_shot_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_few_shot_prompt.csv\", sep = \",\")\n",
    "y_pred_GPT4_vignette_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_vignette_prompt.csv\", sep = \",\")\n",
    "\n",
    "# convert to array\n",
    "y_pred_GPT4_simple_prompt = y_pred_GPT4_simple_prompt[\"y_pred\"].to_numpy()\n",
    "y_pred_GPT4_class_definition_prompt = y_pred_GPT4_class_definition_prompt[\"y_pred\"].to_numpy()\n",
    "y_pred_GPT4_profiled_simple_prompt = y_pred_GPT4_profiled_simple_prompt[\"y_pred\"].to_numpy()\n",
    "y_pred_GPT4_few_shot_prompt = y_pred_GPT4_few_shot_prompt[\"y_pred\"].to_numpy()\n",
    "y_pred_GPT4_vignette_prompt = y_pred_GPT4_vignette_prompt[\"y_pred\"].to_numpy()"
   ],
   "id": "187e592c37102291",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:31:42.846108Z",
     "start_time": "2025-05-16T09:31:42.829275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# indentify misclassified cases by comparing y_pred_GPT4_XXX and y_test, save index\n",
    "misclassified_cases_simple = []\n",
    "misclassified_cases_class_def = []\n",
    "misclassified_cases_profiled_simple = []\n",
    "misclassified_cases_few_shot = []\n",
    "misclassified_cases_vignette = []\n",
    "\n",
    "for i in range(len(y_pred_GPT4_simple_prompt)):\n",
    "    if y_pred_GPT4_simple_prompt[i] != y_test.iloc[i]:\n",
    "        misclassified_cases_simple.append(i)\n",
    "total_cases_simple = len(y_pred_GPT4_simple_prompt)\n",
    "misscl_cases_simple = len(misclassified_cases_simple)\n",
    "correct_clases_simple = total_cases_simple - misscl_cases_simple\n",
    "\n",
    "for i in range(len(y_pred_GPT4_class_definition_prompt)):\n",
    "    if y_pred_GPT4_class_definition_prompt[i] != y_test.iloc[i]:\n",
    "        misclassified_cases_class_def.append(i)\n",
    "total_cases_class_def = len(y_pred_GPT4_class_definition_prompt)\n",
    "misscl_cases_class_def = len(misclassified_cases_class_def)\n",
    "correct_clases_class_def = total_cases_class_def - misscl_cases_class_def\n",
    "\n",
    "for i in range(len(y_pred_GPT4_profiled_simple_prompt)):\n",
    "    if y_pred_GPT4_profiled_simple_prompt[i] != y_test.iloc[i]:\n",
    "        misclassified_cases_profiled_simple.append(i)\n",
    "total_cases_profiled = len(y_pred_GPT4_profiled_simple_prompt)\n",
    "misscl_cases_profiled = len(misclassified_cases_profiled_simple)\n",
    "correct_clases_profiled = total_cases_profiled - misscl_cases_profiled\n",
    "\n",
    "for i in range(len(y_pred_GPT4_few_shot_prompt)):\n",
    "    if y_pred_GPT4_few_shot_prompt[i] != y_test.iloc[i]:\n",
    "        misclassified_cases_few_shot.append(i)\n",
    "total_cases_few_shot = len(y_pred_GPT4_few_shot_prompt)\n",
    "misscl_cases_few_shot = len(misclassified_cases_few_shot)\n",
    "correct_clases_few_shot = total_cases_few_shot - misscl_cases_few_shot\n",
    "\n",
    "for i in range(len(y_pred_GPT4_vignette_prompt)):\n",
    "    if y_pred_GPT4_vignette_prompt[i] != y_test.iloc[i]:\n",
    "        misclassified_cases_vignette.append(i)\n",
    "total_cases_vignette = len(y_pred_GPT4_vignette_prompt)\n",
    "misscl_cases_vignette = len(misclassified_cases_vignette)\n",
    "correct_clases_vignette = total_cases_vignette - misscl_cases_vignette"
   ],
   "id": "3aa9a0da4c196d87",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:31:44.758348Z",
     "start_time": "2025-05-16T09:31:44.744777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save as df with total, correct and missclassified cases\n",
    "simple_cases_df = pd.DataFrame({\"total\": [total_cases_simple], \"correct\": [correct_clases_simple], \"missclassified\": [misscl_cases_simple]})\n",
    "simple_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/simple_cases_GPT_df.csv\", sep = \",\", index = True)\n",
    "\n",
    "class_def_cases_df = pd.DataFrame({\"total\": [total_cases_class_def], \"correct\": [correct_clases_class_def], \"missclassified\": [misscl_cases_class_def]})\n",
    "class_def_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/class_def_cases_GPT_df.csv\", sep = \",\", index = True)\n",
    "\n",
    "profiled_cases_df = pd.DataFrame({\"total\": [total_cases_profiled], \"correct\": [correct_clases_profiled], \"missclassified\": [misscl_cases_profiled]})\n",
    "profiled_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/profiled_cases_GPT_df.csv\", sep = \",\", index = True)\n",
    "\n",
    "few_shot_cases_df = pd.DataFrame({\"total\": [total_cases_few_shot], \"correct\": [correct_clases_few_shot], \"missclassified\": [misscl_cases_few_shot]})\n",
    "few_shot_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/few_shot_cases_GPT_df.csv\", sep = \",\", index = True)\n",
    "\n",
    "vignette_cases_df = pd.DataFrame({\"total\": [total_cases_vignette], \"correct\": [correct_clases_vignette], \"missclassified\": [misscl_cases_vignette]})\n",
    "vignette_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/vignette_cases_GPT_df.csv\", sep = \",\", index = True)\n"
   ],
   "id": "7b6031706cb820c3",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:59:49.001457Z",
     "start_time": "2025-05-16T08:44:53.962430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# simple_prompt_reasons = []\n",
    "# class_def_prompt_reasons = []\n",
    "# profiled_simple_prompt_reasons = []\n",
    "# few_shot_prompt_reasons = []\n",
    "# vignette_prompt_reasons = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# instruction_reason = \"Please categorize why you misclassified the data. Respond only with the following categories as reasons for the misclassification in order to improve prompting. Possible categories are: \\nLack of context (emphasize or indicate the context of the query), \\nLack of examples (few-shot prompting with several examples of appropriate responses are shown before posing the actual question missing), \\nLack of feedback (interactive refining the prompt), \\nLack of counterfactual demonstrations (instances containing false facts to improve faithfulness in knowledge conflict situations), \\nLack of opinion-based information (reframe the context as a narrator’s statement and inquire about the narrator’s opinions), \\nKnowledge conflicts (memorized facts became outdated and counterfactual facts), \\nPrediction with Abstention (model is uncertain about their predictions) \\n \\n Do not mention specific change (e.g., increase or decrease) in predictors, do not go into detail of this specific case and do not repeat the question. Only respond with one or multiple of the categories as reasons for the misclassification, separated by ','. Mention the most important category first.\"\n",
    "#\n",
    "# # iterate over the misclassified cases and save the response for each prompt in an array\n",
    "# print(\"Simple prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_simple:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_simple_prompt[i]} Response: {y_pred_GPT4_simple_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     simple_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# print(\"\\n \\n Class definition prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_class_def:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_class_definitions_prompt[i]} Response: {y_pred_GPT4_class_definition_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     class_def_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# print(\"\\n \\n Profiled simple prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_profiled_simple:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_profiled_simple_prompt[i]} Response: {y_pred_GPT4_profiled_simple_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     profiled_simple_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# print(\"\\n \\n Few shot prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_few_shot:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_few_shot_prompt[i]} Response: {y_pred_GPT4_few_shot_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     few_shot_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# print(\"\\n \\n Vignette prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_vignette:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_vignette_prompt[i]} Response: {y_pred_GPT4_vignette_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     vignette_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)"
   ],
   "id": "286fbda7d1c1de5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple prompt: \n",
      " \n",
      "\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "Lack of context, Lack of feedback.\n",
      "Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of examples, Lack of context\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Knowledge conflicts\n",
      "Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples, Knowledge conflicts\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of feedback\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of feedback\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of feedback, Prediction with Abstention\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention.\n",
      "Lack of context, Prediction with Abstention.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Lack of counterfactual demonstrations\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context\n",
      "Prediction with Abstention, Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples, Knowledge conflicts\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "\n",
      " \n",
      " Class definition prompt: \n",
      " \n",
      "\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of feedback\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of feedback, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context.\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Prediction with Abstention.\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Lack of feedback\n",
      "Lack of context, Lack of feedback, Prediction with Abstention\n",
      "Lack of context.\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "\n",
      " \n",
      " Profiled simple prompt: \n",
      " \n",
      "\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of feedback\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of feedback\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Knowledge conflicts\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of counterfactual demonstrations, Lack of context, Prediction with Abstention.\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "\n",
      " \n",
      " Few shot prompt: \n",
      " \n",
      "\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "Lack of context, Lack of examples\n",
      "Lack of examples, Lack of context\n",
      "Lack of examples\n",
      "Lack of examples\n",
      "Lack of examples, Lack of context\n",
      "Lack of examples, Lack of context\n",
      "Lack of feedback, Lack of context\n",
      "Lack of context, Lack of examples, Knowledge conflicts\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples.\n",
      "Lack of examples, Lack of context\n",
      "Lack of examples\n",
      "Lack of examples, Lack of context\n",
      "Lack of examples, Lack of context\n",
      "Lack of examples, Lack of context\n",
      "Lack of examples, Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of feedback\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "Lack of examples, Lack of context.\n",
      "Lack of examples\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of feedback\n",
      "Lack of examples, Lack of context\n",
      "Lack of context, Lack of examples.\n",
      "Lack of examples, Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of examples\n",
      "Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of examples, Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of examples\n",
      "Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of examples, Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of examples, Lack of context\n",
      "Lack of examples, Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of examples, Lack of context\n",
      "Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of examples, Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of examples\n",
      "Lack of feedback, Lack of context\n",
      "Lack of examples\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "\n",
      " \n",
      " Vignette prompt: \n",
      " \n",
      "\n",
      "Lack of context, Prediction with Abstention.\n",
      "Lack of context, Lack of examples.\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Knowledge conflicts.\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Prediction with Abstention.\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Knowledge conflicts.\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context, Prediction with Abstention, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Knowledge conflicts, Lack of context, Prediction with Abstention\n",
      "Lack of context, Lack of counterfactual demonstrations.\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context, Prediction with Abstention.\n",
      "Lack of context\n",
      "Lack of context, Lack of counterfactual demonstrations\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Knowledge conflicts\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context\n",
      "Lack of context\n",
      "Lack of context, Knowledge conflicts.\n",
      "Lack of context, Lack of examples, Knowledge conflicts\n",
      "Lack of context\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "Lack of context\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context, Lack of examples\n",
      "Knowledge conflicts\n",
      "Lack of context\n",
      "Lack of context, Lack of examples, Lack of feedback\n",
      "Lack of context, Lack of examples\n",
      "Lack of context, Lack of examples\n",
      "Lack of context\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context, Lack of feedback\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of counterfactual demonstrations, Lack of context.\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context, Lack of feedback\n",
      "Lack of context, Lack of examples, Prediction with Abstention\n",
      "Lack of context\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context, Prediction with Abstention.\n",
      "Lack of context, Prediction with Abstention\n",
      "Lack of context, Knowledge conflicts.\n",
      "Prediction with Abstention, Lack of context\n",
      "Lack of context, Lack of examples, Lack of counterfactual demonstrations.\n",
      "Lack of context, Knowledge conflicts\n",
      "Lack of context, Lack of counterfactual demonstrations\n",
      "Lack of context\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:09:12.287310Z",
     "start_time": "2025-05-16T09:09:12.266668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_reasons_simple = []\n",
    "all_reasons_class_def = []\n",
    "all_reasons_profiled_simple = []\n",
    "all_reasons_few_shot = []\n",
    "all_reasons_vignette = []\n",
    "\n",
    "for reason in simple_prompt_reasons:\n",
    "    reason = reason.split(\", \")\n",
    "    reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "    all_reasons_simple.append(reason)\n",
    "\n",
    "for reason in class_def_prompt_reasons:\n",
    "    reason = reason.split(\", \")\n",
    "    reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "    all_reasons_class_def.append(reason)\n",
    "\n",
    "for reason in profiled_simple_prompt_reasons:\n",
    "    reason = reason.split(\", \")\n",
    "    reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "    all_reasons_profiled_simple.append(reason)\n",
    "\n",
    "for reason in few_shot_prompt_reasons:\n",
    "    reason = reason.split(\", \")\n",
    "    reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "    all_reasons_few_shot.append(reason)\n",
    "\n",
    "for reason in vignette_prompt_reasons:\n",
    "    reason = reason.split(\", \")\n",
    "    reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "    all_reasons_vignette.append(reason)"
   ],
   "id": "eda04f93a440ac40",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:09:43.795328Z",
     "start_time": "2025-05-16T09:09:43.778305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simple_prompt_reasons_dict = {}\n",
    "class_def_prompt_reasons_dict = {}\n",
    "profiled_simple_prompt_reasons_dict = {}\n",
    "few_shot_prompt_reasons_dict = {}\n",
    "vignette_prompt_reasons_dict = {}\n",
    "\n",
    "for i in all_reasons_simple:\n",
    "    for j in i:\n",
    "        # count the occurrences of each reason\n",
    "        if j in simple_prompt_reasons_dict:\n",
    "            simple_prompt_reasons_dict[j] += 1\n",
    "        else:\n",
    "            simple_prompt_reasons_dict[j] = 1\n",
    "simple_prompt_reasons_df = pd.DataFrame.from_dict(simple_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# simple_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/simple_prompt_reasons.csv\", sep = \",\", index = True)\n",
    "\n",
    "\n",
    "for i in all_reasons_class_def:\n",
    "    for j in i:\n",
    "        # count the occurrences of each reason\n",
    "        if j in class_def_prompt_reasons_dict:\n",
    "            class_def_prompt_reasons_dict[j] += 1\n",
    "        else:\n",
    "            class_def_prompt_reasons_dict[j] = 1\n",
    "class_def_prompt_reasons_df = pd.DataFrame.from_dict(class_def_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# class_def_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/class_def_prompt_reasons.csv\", sep = \",\", index = True)\n",
    "\n",
    "for i in all_reasons_profiled_simple:\n",
    "    for j in i:\n",
    "        # count the occurrences of each reason\n",
    "        if j in profiled_simple_prompt_reasons_dict:\n",
    "            profiled_simple_prompt_reasons_dict[j] += 1\n",
    "        else:\n",
    "            profiled_simple_prompt_reasons_dict[j] = 1\n",
    "profiled_simple_prompt_reasons_df = pd.DataFrame.from_dict(profiled_simple_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# profiled_simple_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/profiled_simple_prompt_reasons.csv\", sep = \",\", index = True)\n",
    "\n",
    "\n",
    "for i in all_reasons_few_shot:\n",
    "    for j in i:\n",
    "        # count the occurrences of each reason\n",
    "        if j in few_shot_prompt_reasons_dict:\n",
    "            few_shot_prompt_reasons_dict[j] += 1\n",
    "        else:\n",
    "            few_shot_prompt_reasons_dict[j] = 1\n",
    "few_shot_prompt_reasons_df = pd.DataFrame.from_dict(few_shot_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# few_shot_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/few_shot_prompt_reasons.csv\", sep = \",\", index = True)\n",
    "\n",
    "for i in all_reasons_vignette:\n",
    "    for j in i:\n",
    "        # count the occurrences of each reason\n",
    "        if j in vignette_prompt_reasons_dict:\n",
    "            vignette_prompt_reasons_dict[j] += 1\n",
    "        else:\n",
    "            vignette_prompt_reasons_dict[j] = 1\n",
    "vignette_prompt_reasons_df = pd.DataFrame.from_dict(vignette_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# vignette_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/vignette_prompt_reasons.csv\", sep = \",\", index = True)"
   ],
   "id": "953f9cd49f772076",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:14:20.347005Z",
     "start_time": "2025-05-16T09:14:20.339495Z"
    }
   },
   "cell_type": "code",
   "source": "vignette_prompt_reasons_df",
   "id": "8fa6d9b88fe80107",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       count\n",
       "Lack of context                           69\n",
       "Prediction with Abstention                17\n",
       "Lack of examples                          20\n",
       "Knowledge conflicts                       18\n",
       "Lack of counterfactual demonstrations      5\n",
       "Lack of feedback                           4"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lack of context</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction with Abstention</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lack of examples</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knowledge conflicts</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lack of counterfactual demonstrations</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lack of feedback</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:09:47.423717Z",
     "start_time": "2025-05-16T09:09:47.419545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(simple_prompt_reasons_dict, \"\\n \\n\")\n",
    "print(class_def_prompt_reasons_dict, \"\\n \\n\")\n",
    "print(profiled_simple_prompt_reasons_dict, \"\\n \\n\")\n",
    "print(few_shot_prompt_reasons_dict, \"\\n \\n\")\n",
    "print(vignette_prompt_reasons_dict)"
   ],
   "id": "a17c7952d84333ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lack of context': 85, 'Lack of examples': 48, 'Lack of feedback': 6, 'Prediction with Abstention': 18, 'Knowledge conflicts': 5, 'Lack of counterfactual demonstrations': 1} \n",
      " \n",
      "\n",
      "{'Lack of context': 85, 'Lack of examples': 17, 'Prediction with Abstention': 7, 'Lack of feedback': 4, 'Knowledge conflicts': 1} \n",
      " \n",
      "\n",
      "{'Lack of context': 78, 'Lack of examples': 46, 'Lack of feedback': 5, 'Prediction with Abstention': 5, 'Knowledge conflicts': 1, 'Lack of counterfactual demonstrations': 1} \n",
      " \n",
      "\n",
      "{'Lack of context': 83, 'Lack of examples': 84, 'Lack of feedback': 7, 'Knowledge conflicts': 1, 'Prediction with Abstention': 5} \n",
      " \n",
      "\n",
      "{'Lack of context': 69, 'Prediction with Abstention': 17, 'Lack of examples': 20, 'Knowledge conflicts': 18, 'Lack of counterfactual demonstrations': 5, 'Lack of feedback': 4}\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "36a05f87c5fa026e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 Gemini (Google)",
   "id": "603d4a5c922bb11d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:59:49.443452Z",
     "start_time": "2025-05-16T08:59:49.439498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# client = genai.Client(api_key = os.environ.get(\"GEMINI_API_KEY\"))\n",
    "#\n",
    "# response = client.models.generate_content(\n",
    "#     model = \"gemini-2.0-flash\",\n",
    "#     contents = \"Explain how AI works in a few words\",\n",
    "# )\n",
    "#\n",
    "# print(response.text)"
   ],
   "id": "db7c84d6d0cf7c",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:59:49.549976Z",
     "start_time": "2025-05-16T08:59:49.547014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# client = genai.Client(api_key = os.environ.get(\"GEMINI_API_KEY\"))\n",
    "#\n",
    "# response = client.models.generate_content(\n",
    "#     model = \"gemini-2.0-flash\",\n",
    "#     config = types.GenerateContentConfig(\n",
    "#         system_instruction = simple_instruction),\n",
    "#     contents = simple_prompt\n",
    "# )\n",
    "\n",
    "# # gemini-2.5-pro-preview-05-06"
   ],
   "id": "b921335db7bb8d34",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 Gemma (Google)",
   "id": "2121e6074cbc6d60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:59:49.620404Z",
     "start_time": "2025-05-16T08:59:49.618017Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ec22e26e6d7db2ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.4 Llama (Meta)",
   "id": "f599161aabc9b77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:59:49.693266Z",
     "start_time": "2025-05-16T08:59:49.690448Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "325176ecf397915c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.5 Claude (Anthropic)",
   "id": "c4e1b70cdbf6eee3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:59:49.762130Z",
     "start_time": "2025-05-16T08:59:49.759928Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "42f91f18bea3b4ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.6 DeepSeek",
   "id": "67c94f3e4d544889"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:59:49.834052Z",
     "start_time": "2025-05-16T08:59:49.830815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# client = OpenAI(api_key = os.environ.get(\"DeepSeek_API_Key\"), base_url = \"https://api.deepseek.com\")\n",
    "#\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"deepseek-chat\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "#     ],\n",
    "#     stream=False\n",
    "# )\n",
    "#\n",
    "# print(response.choices[0].message.content)"
   ],
   "id": "72f8f909a923d996",
   "outputs": [],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
