{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning: Naive Bayes",
   "id": "38caf9bfc87b9b8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0 Imports",
   "id": "98d6f6cae07aae4f"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-12T09:19:25.388933Z",
     "start_time": "2025-05-12T09:19:25.384320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, recall_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "id": "ae67d5fc0ce4fb14",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T09:16:51.172251Z",
     "start_time": "2025-05-12T09:16:51.126345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"../dat/dips/DIPS_Data_cleaned.csv\", sep = \",\", low_memory = False)\n",
    "data_change = pd.read_csv(\"../dat/dips/DIPS_Data_cleaned_change.csv\", sep = \",\", low_memory = False)\n",
    "data_pred = pd.read_csv(\"../dat/dips/DIPS_Data_cleaned_pred.csv\", sep = \",\", low_memory = False)\n",
    "data_pred_y = pd.read_csv(\"../dat/dips/DIPS_Data_cleaned_pred_y.csv\", sep = \",\", low_memory = False)"
   ],
   "id": "73cbface58315a97",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "67e1622776cab617"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1 Logistic Regression Model",
   "id": "2b43f2e9d2be64ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T09:16:53.348436Z",
     "start_time": "2025-05-12T09:16:53.337281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predictors\n",
    "X = data_change\n",
    "X = X.drop([\"hpi\"], axis = 1)\n",
    "\n",
    "# Target\n",
    "y = data_change[\"hpi\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "print(\"Logistic Regression \\n\",\n",
    "      \"X_train shape: \", X_train.shape, round(X_train.shape[0]/len(X), 2), \"\\n\",\n",
    "      \"X_test shape: \", X_test.shape, round(X_test.shape[0]/len(X), 2),  \"\\n\",\n",
    "      \"y_train shape: \", y_train.shape, round(y_train.shape[0]/len(y), 2), \"\\n\",\n",
    "      \"y_test shape: \", y_test.shape, round(y_test.shape[0]/len(y), 2), \"\\n\")"
   ],
   "id": "8388bc1bb9da6202",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      " X_train shape:  (983, 22) 0.8 \n",
      " X_test shape:  (246, 22) 0.2 \n",
      " y_train shape:  (983,) 0.8 \n",
      " y_test shape:  (246,) 0.2 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T09:18:46.600263Z",
     "start_time": "2025-05-12T09:18:46.593301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sklearn_naive_bayes(x_test_nb, x_train_nb, y_train_nb, y_test_nb):\n",
    "    \"\"\"Computes OLS weights for linear regression without regularization using the sklearn library on the training set and\n",
    "       returns weights, testset predictions and metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1: GRID SEARCH\n",
    "    gnb_model = GaussianNB()\n",
    "    param_grid = {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "    }\n",
    "    grid_search = GridSearchCV(estimator = gnb_model, param_grid = param_grid, cv = 10)\n",
    "    grid_search.fit(x_train_nb, y_train_nb)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "    # 2: FITTING THE MODEL\n",
    "    model = GaussianNB(var_smoothing = best_model.var_smoothing)\n",
    "    model.fit(x_train_nb, y_train_nb)\n",
    "\n",
    "    # 3: ESTIMATING WEIGHTS\n",
    "    weights_nb = model.theta_\n",
    "    features_nb = model.feature_names_in_\n",
    "\n",
    "    # 4: COMPUTE TEST SET PREDICTIONS\n",
    "    y_pred_nb = model.predict(x_test_nb)\n",
    "    y_pred_proba_nb = model.predict_proba(x_test_nb)\n",
    "\n",
    "    # 5: COMPUTE METRICS\n",
    "    accuracy_nb = model.score(x_test_nb, y_test_nb)\n",
    "    macro_f1_nb = recall_score(y_test_nb, y_pred_nb, average = \"macro\")\n",
    "    micro_f1_nb = recall_score(y_test_nb, y_pred_nb, average = \"micro\")\n",
    "    mcc_nb = matthews_corrcoef(y_test_nb, y_pred_nb)\n",
    "\n",
    "    cm_nb = confusion_matrix(y_test_nb, y_pred_nb)\n",
    "    precision_nb = cm_nb[1][1] / (cm_nb[1][1] + cm_nb[0][1])\n",
    "    recall_nb = cm_nb[1][1] / (cm_nb[1][1] + cm_nb[1][0])\n",
    "\n",
    "    # store metrics in a dictionary\n",
    "    metrics_nb = {\n",
    "        \"accuracy\": round(accuracy_nb, 4),\n",
    "        \"macro_f1\": round(macro_f1_nb, 4),\n",
    "        \"micro_f1\": round(micro_f1_nb, 4),\n",
    "        \"mcc\": round(mcc_nb, 4),\n",
    "        \"precision\": round(precision_nb, 4),\n",
    "        \"recall\": round(recall_nb, 4),\n",
    "        \"confusion_matrix\": cm_nb\n",
    "    }\n",
    "\n",
    "    return weights_nb, y_pred_nb, features_nb, metrics_nb"
   ],
   "id": "bbc151d4aeb7eaf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T09:22:46.962779Z",
     "start_time": "2025-05-12T09:22:46.793365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "\n",
    "weights_naive, y_pred_naive, features_naive, metrics_naive = sklearn_naive_bayes(X_test, X_train, y_train, y_test)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time: \", {end - start}, \"seconds\")\n",
    "time_nb = end - start\n",
    "time_nb_df = pd.DataFrame({\"time\": [time_nb]})\n",
    "time_nb_df.to_csv(\"../exp/times_ML/time_nb.csv\", sep = \",\", index = False)\n",
    "\n",
    "# save weights and predictions\n",
    "# weights_naive = pd.DataFrame([weights_naive], columns = features_naive)\n",
    "# weights_naive.to_csv(\"../exp/weights/weights_nb.csv\", sep = \",\", index = False)\n",
    "\n",
    "y_pred_naive = pd.DataFrame(y_pred_naive, columns = [\"y_pred\"])\n",
    "y_pred_naive.to_csv(\"../exp/predictions/y_pred_nb.csv\", sep = \",\", index = False)"
   ],
   "id": "9e2c6468be3ccd11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'var_smoothing': 1e-09}\n",
      "Best score:  0.6968047825190682\n",
      "Execution time:  {0.16225695610046387} seconds\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ec27220c6a44774"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
