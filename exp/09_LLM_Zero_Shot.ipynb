{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LLM: Zero-shot classification through LLMs and prompts",
   "id": "dd0560725aae3b41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Models**:\n",
    "\n",
    "- GPT-4o (OpenAI)\n",
    "- Gemini (Google)\n",
    "- Gemma (Google)\n",
    "- Llama (Meta)\n",
    "- Claude (Anthropic)\n",
    "- DeepSeek\n"
   ],
   "id": "d7a620a322cdfbae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0 Imports",
   "id": "cc42939b0f2e6112"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:21:30.164650Z",
     "start_time": "2025-05-18T15:21:26.905945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import anthropic\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import pdist"
   ],
   "id": "2aaae4e734b1e3c4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:21:30.359913Z",
     "start_time": "2025-05-18T15:21:30.242586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test_simple_prompt_df = pd.read_csv(\"../dat/prompts/X_test_simple_prompt.csv\", sep = \",\", index_col = 0)\n",
    "X_test_class_definitions_prompt_df = pd.read_csv(\"../dat/prompts/X_test_class_definitions_prompt.csv\", sep = \",\", index_col = 0)\n",
    "X_test_profiled_simple_prompt_df = pd.read_csv(\"../dat/prompts/X_test_profiled_simple_prompt.csv\", sep = \",\", index_col = 0)\n",
    "X_test_few_shot_prompt_df = pd.read_csv(\"../dat/prompts/X_test_few_shot_prompt.csv\", sep = \",\", index_col = 0)\n",
    "X_test_vignette_prompt_df = pd.read_csv(\"../dat/prompts/X_test_vignette_prompt.csv\", sep = \",\", index_col = 0)\n",
    "X_test_claude_prompt_df = pd.read_csv(\"../dat/prompts/X_test_claude_prompt.csv\", sep = \",\", index_col = 0)"
   ],
   "id": "6f52bfed5f097045",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:21:30.868595Z",
     "start_time": "2025-05-18T15:21:30.861218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert to arrays\n",
    "X_test_simple_prompt = X_test_simple_prompt_df.values.flatten()\n",
    "X_test_class_definitions_prompt = X_test_class_definitions_prompt_df.values.flatten()\n",
    "X_test_profiled_simple_prompt = X_test_profiled_simple_prompt_df.values.flatten()\n",
    "X_test_few_shot_prompt = X_test_few_shot_prompt_df.values.flatten()\n",
    "X_test_vignette_prompt = X_test_vignette_prompt_df.values.flatten()\n",
    "X_test_claude_prompt = X_test_claude_prompt_df.values.flatten()"
   ],
   "id": "817be744e50093b5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:21:31.709290Z",
     "start_time": "2025-05-18T15:21:31.701417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simple_instruction = \"Respond only with YES or NO.\"\n",
    "class_definitions_instruction = \"Respond only with YES or NO.\"\n",
    "profiled_simple_instruction = \"Respond only with YES or NO.\"\n",
    "few_shot_instruction = \"Respond only with YES or NO.\"\n",
    "vignette_instruction = \"Respond only with YES or NO.\"\n",
    "claude_instruction = \"You are an expert psychologist tasked with predicting whether an individual will develop a psychological disorder between two time points (T1 and T2) based on various psychological measures and demographic information. Your goal is to provide an accurate YES or NO prediction, supported by a brief explanation of your reasoning. Example output format: \\n Prediction: [YES/NO] \\n Explanation: [Brief explanation supporting your prediction].\""
   ],
   "id": "42733c2134765065",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b5e409ae0b81dc9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1 Zero-shot classification with LLMs",
   "id": "73ae6d6f42430acd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this section, I will use the prompts created in the previous section to **classify the test set using different LLMs**. The LLMs will be used to classify whether a person develops a psychological disorder between time point T1 and T2.",
   "id": "e7c46aa0e2c9031f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 ChatGPT (OpenAI)",
   "id": "7c184484efa02be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.1.1 Testing prompting",
   "id": "b3181ef2a9c5ad83"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:47.309595Z",
     "start_time": "2025-05-18T13:53:47.304788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # testing\n",
    "# response = client.responses.create(\n",
    "#     model = \"gpt-4o-mini\",\n",
    "#     instructions = \"You are a coding assistant that talks like a pirate.\",\n",
    "#     input = \"How do I check if a Python object is an instance of a class?\",\n",
    "# )\n",
    "#\n",
    "# print(response.output_text)"
   ],
   "id": "738fb998b35415c6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f96758305e52ce67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.1.2. Prompting with ChatGPT-4o",
   "id": "34bf1926b6e19c7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:47.695161Z",
     "start_time": "2025-05-18T13:53:47.690386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# simple_prompt_y_pred_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_simple_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = simple_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     simple_prompt_y_pred_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_simple_prompt = end - start\n",
    "# time_GPT_simple_prompt_df = pd.DataFrame({\"time\": [time_GPT_simple_prompt]})\n",
    "# time_GPT_simple_prompt_df.to_csv(\"../exp/times_LLMs/GPT4/time_GPT4_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_simple_GPT = pd.Series(simple_prompt_y_pred_GPT).value_counts()\n",
    "# print(counts_simple_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# simple_prompt_y_pred_GPT = [1 if response == \"YES\" else 0 if response == \"NO\" else np.nan for response in simple_prompt_y_pred_GPT]\n",
    "# simple_prompt_y_pred_GPT\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# simple_prompt_df_GPT = pd.DataFrame(simple_prompt_y_pred_GPT, columns = [\"y_pred\"])\n",
    "# simple_prompt_df_GPT.to_csv(\"../exp/preds_LLMs/GPT4/y_pred_GPT4_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "bff465ba605628f4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:48.059799Z",
     "start_time": "2025-05-18T13:53:48.055372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class_def_y_pred_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_class_definitions_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = class_definitions_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     class_def_y_pred_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_class_definitions = end - start\n",
    "# time_GPT_class_definitions_df = pd.DataFrame({\"time\": [time_GPT_class_definitions]})\n",
    "# time_GPT_class_definitions_df.to_csv(\"../exp/times_LLMs/GPT4/time_GPT4_class_definitions_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_class_def_GPT = pd.Series(class_def_y_pred_GPT).value_counts()\n",
    "# print(counts_class_def_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# class_def_y_pred_GPT = [1 if response == \"YES\" else 0 for response in class_def_y_pred_GPT]\n",
    "# class_def_y_pred_GPT\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# class_def_df_GPT = pd.DataFrame(class_def_y_pred_GPT, columns = [\"y_pred\"])\n",
    "# class_def_df_GPT.to_csv(\"../exp/preds_LLMs/GPT4/y_pred_GPT4_class_definitions_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "63f70e77e37a9919",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:48.434204Z",
     "start_time": "2025-05-18T13:53:48.430468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# profiled_simple_y_pred_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_profiled_simple_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = profiled_simple_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     profiled_simple_y_pred_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_profiled_simple = end - start\n",
    "# time_GPT_profiled_simple_df = pd.DataFrame({\"time\": [time_GPT_profiled_simple]})\n",
    "# time_GPT_profiled_simple_df.to_csv(\"../exp/times_LLMs/GPT4/time_GPT4_profiled_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_profiled_simple_GPT = pd.Series(profiled_simple_y_pred_GPT).value_counts()\n",
    "# print(counts_profiled_simple_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# profiled_simple_y_pred_GPT_val = [1 if response == \"YES\" else 0 for response in profiled_simple_y_pred_GPT]\n",
    "# profiled_simple_y_pred_GPT_val\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# profiled_simple_df_GPT = pd.DataFrame(profiled_simple_y_pred_GPT_val, columns = [\"y_pred\"])\n",
    "# profiled_simple_df_GPT.to_csv(\"../exp/preds_LLMs/GPT4/y_pred_GPT4_profiled_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "8fff5eef0784f0bf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:48.801391Z",
     "start_time": "2025-05-18T13:53:48.796663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# few_shot_y_pred_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_few_shot_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = few_shot_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     few_shot_y_pred_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_few_shot = end - start\n",
    "# time_GPT_few_shot_df = pd.DataFrame({\"time\": [time_GPT_few_shot]})\n",
    "# time_GPT_few_shot_df.to_csv(\"../exp/times_LLMs/GPT4/time_GPT4_few_shot_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_few_shot_GPT = pd.Series(few_shot_y_pred_GPT).value_counts()\n",
    "# print(counts_few_shot_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# few_shot_y_pred_GPT_val = [1 if response == \"YES\" else 0 for response in few_shot_y_pred_GPT]\n",
    "# few_shot_y_pred_GPT_val\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# few_shot_df_GPT = pd.DataFrame(few_shot_y_pred_GPT_val, columns = [\"y_pred\"])\n",
    "# few_shot_df_GPT.to_csv(\"../exp/preds_LLMs/GPT4/y_pred_GPT4_few_shot_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "f7389ea105f9761b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:49.144140Z",
     "start_time": "2025-05-18T13:53:49.140437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# vignette_y_pred_GPT = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_vignette_prompt:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = vignette_instruction,\n",
    "#         input = prompt,\n",
    "#     )\n",
    "#     vignette_y_pred_GPT.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_GPT_vignette = end - start\n",
    "# time_GPT_vignette_df = pd.DataFrame({\"time\": [time_GPT_vignette]})\n",
    "# time_GPT_vignette_df.to_csv(\"../exp/times_LLMs/GPT4/time_GPT4_vignette_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_vignette_GPT = pd.Series(vignette_y_pred_GPT).value_counts()\n",
    "# print(counts_vignette_GPT)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# vignette_y_pred_GPT_val = [1 if response == \"YES\" else 0 for response in vignette_y_pred_GPT]\n",
    "# vignette_y_pred_GPT_val\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# vignette_df_GPT = pd.DataFrame(vignette_y_pred_GPT_val, columns = [\"y_pred\"])\n",
    "# vignette_df_GPT.to_csv(\"../exp/preds_LLMs/GPT4/y_pred_GPT4_vignette_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "11d6cfb1d391ec89",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.1.3 Misclassified cases reasons",
   "id": "1af0af9d4db4cb1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:49.508806Z",
     "start_time": "2025-05-18T13:53:49.505727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# y_pred_GPT4_simple_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_simple_prompt.csv\", sep = \",\")\n",
    "# y_pred_GPT4_class_definition_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_class_definitions_prompt.csv\", sep = \",\")\n",
    "# y_pred_GPT4_profiled_simple_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_profiled_simple_prompt.csv\", sep = \",\")\n",
    "# y_pred_GPT4_few_shot_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_few_shot_prompt.csv\", sep = \",\")\n",
    "# y_pred_GPT4_vignette_prompt = pd.read_csv(\"../exp/preds_LLMs/y_pred_GPT4_vignette_prompt.csv\", sep = \",\")\n",
    "#\n",
    "# # convert to array\n",
    "# y_pred_GPT4_simple_prompt = y_pred_GPT4_simple_prompt[\"y_pred\"].to_numpy()\n",
    "# y_pred_GPT4_class_definition_prompt = y_pred_GPT4_class_definition_prompt[\"y_pred\"].to_numpy()\n",
    "# y_pred_GPT4_profiled_simple_prompt = y_pred_GPT4_profiled_simple_prompt[\"y_pred\"].to_numpy()\n",
    "# y_pred_GPT4_few_shot_prompt = y_pred_GPT4_few_shot_prompt[\"y_pred\"].to_numpy()\n",
    "# y_pred_GPT4_vignette_prompt = y_pred_GPT4_vignette_prompt[\"y_pred\"].to_numpy()"
   ],
   "id": "187e592c37102291",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:49.869783Z",
     "start_time": "2025-05-18T13:53:49.866035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # indentify misclassified cases by comparing y_pred_GPT4_XXX and y_test, save index\n",
    "# misclassified_cases_simple = []\n",
    "# misclassified_cases_class_def = []\n",
    "# misclassified_cases_profiled_simple = []\n",
    "# misclassified_cases_few_shot = []\n",
    "# misclassified_cases_vignette = []\n",
    "#\n",
    "# for i in range(len(y_pred_GPT4_simple_prompt)):\n",
    "#     if y_pred_GPT4_simple_prompt[i] != y_test.iloc[i]:\n",
    "#         misclassified_cases_simple.append(i)\n",
    "# total_cases_simple = len(y_pred_GPT4_simple_prompt)\n",
    "# misscl_cases_simple = len(misclassified_cases_simple)\n",
    "# correct_clases_simple = total_cases_simple - misscl_cases_simple\n",
    "#\n",
    "# for i in range(len(y_pred_GPT4_class_definition_prompt)):\n",
    "#     if y_pred_GPT4_class_definition_prompt[i] != y_test.iloc[i]:\n",
    "#         misclassified_cases_class_def.append(i)\n",
    "# total_cases_class_def = len(y_pred_GPT4_class_definition_prompt)\n",
    "# misscl_cases_class_def = len(misclassified_cases_class_def)\n",
    "# correct_clases_class_def = total_cases_class_def - misscl_cases_class_def\n",
    "#\n",
    "# for i in range(len(y_pred_GPT4_profiled_simple_prompt)):\n",
    "#     if y_pred_GPT4_profiled_simple_prompt[i] != y_test.iloc[i]:\n",
    "#         misclassified_cases_profiled_simple.append(i)\n",
    "# total_cases_profiled = len(y_pred_GPT4_profiled_simple_prompt)\n",
    "# misscl_cases_profiled = len(misclassified_cases_profiled_simple)\n",
    "# correct_clases_profiled = total_cases_profiled - misscl_cases_profiled\n",
    "#\n",
    "# for i in range(len(y_pred_GPT4_few_shot_prompt)):\n",
    "#     if y_pred_GPT4_few_shot_prompt[i] != y_test.iloc[i]:\n",
    "#         misclassified_cases_few_shot.append(i)\n",
    "# total_cases_few_shot = len(y_pred_GPT4_few_shot_prompt)\n",
    "# misscl_cases_few_shot = len(misclassified_cases_few_shot)\n",
    "# correct_clases_few_shot = total_cases_few_shot - misscl_cases_few_shot\n",
    "#\n",
    "# for i in range(len(y_pred_GPT4_vignette_prompt)):\n",
    "#     if y_pred_GPT4_vignette_prompt[i] != y_test.iloc[i]:\n",
    "#         misclassified_cases_vignette.append(i)\n",
    "# total_cases_vignette = len(y_pred_GPT4_vignette_prompt)\n",
    "# misscl_cases_vignette = len(misclassified_cases_vignette)\n",
    "# correct_clases_vignette = total_cases_vignette - misscl_cases_vignette"
   ],
   "id": "3aa9a0da4c196d87",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:50.227113Z",
     "start_time": "2025-05-18T13:53:50.221584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # save as df with total, correct and missclassified cases\n",
    "# simple_cases_df = pd.DataFrame({\"total\": [total_cases_simple], \"correct\": [correct_clases_simple], \"missclassified\": [misscl_cases_simple]})\n",
    "# simple_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/simple_cases_GPT_df.csv\", sep = \",\", index = True)\n",
    "#\n",
    "# class_def_cases_df = pd.DataFrame({\"total\": [total_cases_class_def], \"correct\": [correct_clases_class_def], \"missclassified\": [misscl_cases_class_def]})\n",
    "# class_def_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/class_def_cases_GPT_df.csv\", sep = \",\", index = True)\n",
    "#\n",
    "# profiled_cases_df = pd.DataFrame({\"total\": [total_cases_profiled], \"correct\": [correct_clases_profiled], \"missclassified\": [misscl_cases_profiled]})\n",
    "# profiled_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/profiled_cases_GPT_df.csv\", sep = \",\", index = True)\n",
    "#\n",
    "# few_shot_cases_df = pd.DataFrame({\"total\": [total_cases_few_shot], \"correct\": [correct_clases_few_shot], \"missclassified\": [misscl_cases_few_shot]})\n",
    "# few_shot_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/few_shot_cases_GPT_df.csv\", sep = \",\", index = True)\n",
    "#\n",
    "# vignette_cases_df = pd.DataFrame({\"total\": [total_cases_vignette], \"correct\": [correct_clases_vignette], \"missclassified\": [misscl_cases_vignette]})\n",
    "# vignette_cases_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/vignette_cases_GPT_df.csv\", sep = \",\", index = True)\n"
   ],
   "id": "7b6031706cb820c3",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:50.630900Z",
     "start_time": "2025-05-18T13:53:50.625301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# simple_prompt_reasons = []\n",
    "# class_def_prompt_reasons = []\n",
    "# profiled_simple_prompt_reasons = []\n",
    "# few_shot_prompt_reasons = []\n",
    "# vignette_prompt_reasons = []\n",
    "#\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "#\n",
    "# instruction_reason = \"Please categorize why you misclassified the data. Respond only with the following categories as reasons for the misclassification in order to improve prompting. Possible categories are: \\nLack of context (emphasize or indicate the context of the query), \\nLack of examples (few-shot prompting with several examples of appropriate responses are shown before posing the actual question missing), \\nLack of feedback (interactive refining the prompt), \\nLack of counterfactual demonstrations (instances containing false facts to improve faithfulness in knowledge conflict situations), \\nLack of opinion-based information (reframe the context as a narrator’s statement and inquire about the narrator’s opinions), \\nKnowledge conflicts (memorized facts became outdated and counterfactual facts), \\nPrediction with Abstention (model is uncertain about their predictions) \\n \\n Do not mention specific change (e.g., increase or decrease) in predictors, do not go into detail of this specific case and do not repeat the question. Only respond with one or multiple of the categories as reasons for the misclassification, separated by ','. Mention the most important category first.\"\n",
    "#\n",
    "# # iterate over the misclassified cases and save the response for each prompt in an array\n",
    "# print(\"Simple prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_simple:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_simple_prompt[i]} Response: {y_pred_GPT4_simple_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     simple_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# print(\"\\n \\n Class definition prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_class_def:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_class_definitions_prompt[i]} Response: {y_pred_GPT4_class_definition_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     class_def_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# print(\"\\n \\n Profiled simple prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_profiled_simple:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_profiled_simple_prompt[i]} Response: {y_pred_GPT4_profiled_simple_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     profiled_simple_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# print(\"\\n \\n Few shot prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_few_shot:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_few_shot_prompt[i]} Response: {y_pred_GPT4_few_shot_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     few_shot_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)\n",
    "#\n",
    "# print(\"\\n \\n Vignette prompt: \\n \\n\")\n",
    "# for i in misclassified_cases_vignette:\n",
    "#     response = client.responses.create(\n",
    "#         model = \"gpt-4o\",\n",
    "#         instructions = instruction_reason,\n",
    "#         input = f\"Misclassified case {i}: Prompt: {X_test_vignette_prompt[i]} Response: {y_pred_GPT4_vignette_prompt[i]} True label: {y_test.iloc[i]}\"\n",
    "#     )\n",
    "#     vignette_prompt_reasons.append(response.output_text)\n",
    "#     print(response.output_text)"
   ],
   "id": "286fbda7d1c1de5c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:50.985607Z",
     "start_time": "2025-05-18T13:53:50.980125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# all_reasons_simple = []\n",
    "# all_reasons_class_def = []\n",
    "# all_reasons_profiled_simple = []\n",
    "# all_reasons_few_shot = []\n",
    "# all_reasons_vignette = []\n",
    "#\n",
    "# for reason in simple_prompt_reasons:\n",
    "#     reason = reason.split(\", \")\n",
    "#     reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "#     all_reasons_simple.append(reason)\n",
    "#\n",
    "# for reason in class_def_prompt_reasons:\n",
    "#     reason = reason.split(\", \")\n",
    "#     reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "#     all_reasons_class_def.append(reason)\n",
    "#\n",
    "# for reason in profiled_simple_prompt_reasons:\n",
    "#     reason = reason.split(\", \")\n",
    "#     reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "#     all_reasons_profiled_simple.append(reason)\n",
    "#\n",
    "# for reason in few_shot_prompt_reasons:\n",
    "#     reason = reason.split(\", \")\n",
    "#     reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "#     all_reasons_few_shot.append(reason)\n",
    "#\n",
    "# for reason in vignette_prompt_reasons:\n",
    "#     reason = reason.split(\", \")\n",
    "#     reason = [re.sub(r'[^A-Za-z\\s]', '', r).strip() for r in reason]\n",
    "#     all_reasons_vignette.append(reason)"
   ],
   "id": "eda04f93a440ac40",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:51.324006Z",
     "start_time": "2025-05-18T13:53:51.319540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# simple_prompt_reasons_dict = {}\n",
    "# class_def_prompt_reasons_dict = {}\n",
    "# profiled_simple_prompt_reasons_dict = {}\n",
    "# few_shot_prompt_reasons_dict = {}\n",
    "# vignette_prompt_reasons_dict = {}\n",
    "#\n",
    "# for i in all_reasons_simple:\n",
    "#     for j in i:\n",
    "#         # count the occurrences of each reason\n",
    "#         if j in simple_prompt_reasons_dict:\n",
    "#             simple_prompt_reasons_dict[j] += 1\n",
    "#         else:\n",
    "#             simple_prompt_reasons_dict[j] = 1\n",
    "# simple_prompt_reasons_df = pd.DataFrame.from_dict(simple_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# # simple_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/simple_prompt_reasons.csv\", sep = \",\", index = True)\n",
    "#\n",
    "#\n",
    "# for i in all_reasons_class_def:\n",
    "#     for j in i:\n",
    "#         # count the occurrences of each reason\n",
    "#         if j in class_def_prompt_reasons_dict:\n",
    "#             class_def_prompt_reasons_dict[j] += 1\n",
    "#         else:\n",
    "#             class_def_prompt_reasons_dict[j] = 1\n",
    "# class_def_prompt_reasons_df = pd.DataFrame.from_dict(class_def_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# # class_def_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/class_def_prompt_reasons.csv\", sep = \",\", index = True)\n",
    "#\n",
    "# for i in all_reasons_profiled_simple:\n",
    "#     for j in i:\n",
    "#         # count the occurrences of each reason\n",
    "#         if j in profiled_simple_prompt_reasons_dict:\n",
    "#             profiled_simple_prompt_reasons_dict[j] += 1\n",
    "#         else:\n",
    "#             profiled_simple_prompt_reasons_dict[j] = 1\n",
    "# profiled_simple_prompt_reasons_df = pd.DataFrame.from_dict(profiled_simple_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# # profiled_simple_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/profiled_simple_prompt_reasons.csv\", sep = \",\", index = True)\n",
    "#\n",
    "#\n",
    "# for i in all_reasons_few_shot:\n",
    "#     for j in i:\n",
    "#         # count the occurrences of each reason\n",
    "#         if j in few_shot_prompt_reasons_dict:\n",
    "#             few_shot_prompt_reasons_dict[j] += 1\n",
    "#         else:\n",
    "#             few_shot_prompt_reasons_dict[j] = 1\n",
    "# few_shot_prompt_reasons_df = pd.DataFrame.from_dict(few_shot_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# # few_shot_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/few_shot_prompt_reasons.csv\", sep = \",\", index = True)\n",
    "#\n",
    "# for i in all_reasons_vignette:\n",
    "#     for j in i:\n",
    "#         # count the occurrences of each reason\n",
    "#         if j in vignette_prompt_reasons_dict:\n",
    "#             vignette_prompt_reasons_dict[j] += 1\n",
    "#         else:\n",
    "#             vignette_prompt_reasons_dict[j] = 1\n",
    "# vignette_prompt_reasons_df = pd.DataFrame.from_dict(vignette_prompt_reasons_dict, orient='index', columns=['count'])\n",
    "# # vignette_prompt_reasons_df.to_csv(\"../exp/reasons_misclassifications_LLMs/GPT4/vignette_prompt_reasons.csv\", sep = \",\", index = True)"
   ],
   "id": "953f9cd49f772076",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:51.660345Z",
     "start_time": "2025-05-18T13:53:51.657495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(simple_prompt_reasons_dict, \"\\n \\n\")\n",
    "# print(class_def_prompt_reasons_dict, \"\\n \\n\")\n",
    "# print(profiled_simple_prompt_reasons_dict, \"\\n \\n\")\n",
    "# print(few_shot_prompt_reasons_dict, \"\\n \\n\")\n",
    "# print(vignette_prompt_reasons_dict)"
   ],
   "id": "a17c7952d84333ba",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "36a05f87c5fa026e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Gemini (Google)",
   "id": "603d4a5c922bb11d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2.1 Testing prompting",
   "id": "929a34c8bb3628be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:52.066066Z",
     "start_time": "2025-05-18T13:53:52.063357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# client = genai.Client(api_key = os.environ.get(\"GEMINI_API_KEY\"))\n",
    "#\n",
    "# response = client.models.generate_content(\n",
    "#     model = \"gemini-2.0-flash\",\n",
    "#     contents = \"Explain how AI works in a few words\",\n",
    "# )\n",
    "#\n",
    "# print(response.text)"
   ],
   "id": "db7c84d6d0cf7c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:52.414223Z",
     "start_time": "2025-05-18T13:53:52.411742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# client = genai.Client(api_key = os.environ.get(\"GEMINI_API_KEY\"))\n",
    "#\n",
    "# response = client.models.generate_content(\n",
    "#     model = \"gemini-2.0-flash\",\n",
    "#     config = types.GenerateContentConfig(\n",
    "#         system_instruction = simple_instruction),\n",
    "#     contents = simple_prompt\n",
    "# )\n",
    "#\n",
    "# # gemini-2.5-pro-preview-05-06"
   ],
   "id": "b921335db7bb8d34",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3 Gemma (Google)",
   "id": "2121e6074cbc6d60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:52.736444Z",
     "start_time": "2025-05-18T13:53:52.734383Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ec22e26e6d7db2ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.4 Llama (Meta)",
   "id": "f599161aabc9b77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:53.083700Z",
     "start_time": "2025-05-18T13:53:53.080879Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "325176ecf397915c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.5 Claude (Anthropic)",
   "id": "c4e1b70cdbf6eee3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.5.1 Testing prompting",
   "id": "536d090fb805aeed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:53.458474Z",
     "start_time": "2025-05-18T13:53:53.454782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# client = anthropic.Anthropic(api_key = os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "#\n",
    "# message = client.messages.create(\n",
    "#     model = \"claude-3-7-sonnet-20250219\",\n",
    "#     max_tokens = 20000,\n",
    "#     temperature = 1,\n",
    "#     thinking = {\n",
    "#         \"type\": \"enabled\",\n",
    "#         \"budget_tokens\": 16000\n",
    "#     },\n",
    "#     system = claude_instruction,\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": [\n",
    "#                 {\n",
    "#                     \"type\": \"text\",\n",
    "#                     \"text\": X_test_claude_prompt[0]\n",
    "#                 }\n",
    "#             ]\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# print(message.content)"
   ],
   "id": "42f91f18bea3b4ff",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:53.831410Z",
     "start_time": "2025-05-18T13:53:53.827558Z"
    }
   },
   "cell_type": "code",
   "source": "# print(message.content[0].thinking)",
   "id": "79e3b3290d646d8f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:54.188237Z",
     "start_time": "2025-05-18T13:53:54.182450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prediction = re.findall(r'Prediction: (.*)', message.content[1].text)\n",
    "# prediction[0]"
   ],
   "id": "2e198379eb34a06",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:54.582103Z",
     "start_time": "2025-05-18T13:53:54.578739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # extract what comes after Explanation:\n",
    "# explanation = re.findall(r'Explanation: (.*)', message.content[1].text)\n",
    "# explanation[0]"
   ],
   "id": "fb9e1f526e0ea4fe",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.5.2 Prompting with Claude 3.7 Sonnet",
   "id": "121677042242e32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:54.945425Z",
     "start_time": "2025-05-18T13:53:54.940351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# simple_prompt_y_pred_claude = []\n",
    "# simple_prompt_thinking_claude = []\n",
    "#\n",
    "# client = anthropic.Anthropic(api_key = os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_simple_prompt:\n",
    "#     message = client.messages.create(\n",
    "#         model = \"claude-3-7-sonnet-20250219\",\n",
    "#         max_tokens = 20000,\n",
    "#         temperature = 1,\n",
    "#         thinking = {\n",
    "#             \"type\": \"enabled\",\n",
    "#             \"budget_tokens\": 16000\n",
    "#         },\n",
    "#         system = simple_instruction,\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "#     )\n",
    "#     simple_prompt_y_pred_claude.append(message.content[1].text)\n",
    "#     simple_prompt_thinking_claude.append(message.content[0].thinking)\n",
    "#     print(message.content[1].text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_claude_simple_prompt = end - start\n",
    "# time_claude_simple_prompt_df = pd.DataFrame({\"time\": [time_claude_simple_prompt]})\n",
    "# time_claude_simple_prompt_df.to_csv(\"../exp/times_LLMs/Claude/time_claude_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_simple_claude = pd.Series(simple_prompt_y_pred_claude).value_counts()\n",
    "# print(counts_simple_claude)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# simple_prompt_y_pred_claude = [1 if response == \"YES\" else 0 if response == \"NO\" else np.nan for response in simple_prompt_y_pred_claude]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# simple_prompt_df_claude = pd.DataFrame(simple_prompt_y_pred_claude, columns = [\"y_pred\"])\n",
    "# simple_prompt_df_claude.to_csv(\"../exp/preds_LLMs/Claude/y_pred_claude_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# simple_prompt_df_thinking_claude = pd.DataFrame(simple_prompt_thinking_claude, columns = [\"thinking\"])\n",
    "# simple_prompt_df_thinking_claude.to_csv(\"../exp/preds_LLMs/Claude/Thinking/thinking_claude_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "82b0ac9aa76bd4a3",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:55.280539Z",
     "start_time": "2025-05-18T13:53:55.276871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class_def_y_pred_claude = []\n",
    "# class_def_thinking_claude = []\n",
    "#\n",
    "# client = anthropic.Anthropic(api_key = os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_class_definitions_prompt:\n",
    "#     message = client.messages.create(\n",
    "#         model = \"claude-3-7-sonnet-20250219\",\n",
    "#         max_tokens = 20000,\n",
    "#         temperature = 1,\n",
    "#         thinking = {\n",
    "#             \"type\": \"enabled\",\n",
    "#             \"budget_tokens\": 16000\n",
    "#         },\n",
    "#         system = class_definitions_instruction,\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "#     )\n",
    "#     class_def_y_pred_claude.append(message.content[1].text)\n",
    "#     class_def_thinking_claude.append(message.content[0].thinking)\n",
    "#     print(message.content[1].text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_claude_class_definitions = end - start\n",
    "# time_claude_class_definitions_df = pd.DataFrame({\"time\": [time_claude_class_definitions]})\n",
    "# time_claude_class_definitions_df.to_csv(\"../exp/times_LLMs/Claude/time_claude_class_definitions_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_class_def_claude = pd.Series(class_def_y_pred_claude).value_counts()\n",
    "# print(counts_class_def_claude)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# class_def_y_pred_claude = [1 if response == \"YES\" else 0 for response in class_def_y_pred_claude]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# class_def_df_claude = pd.DataFrame(class_def_y_pred_claude, columns = [\"y_pred\"])\n",
    "# class_def_df_claude.to_csv(\"../exp/preds_LLMs/Claude/y_pred_claude_class_definitions_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# class_def_prompt_df_thinking_claude = pd.DataFrame(class_def_thinking_claude, columns = [\"thinking\"])\n",
    "# class_def_prompt_df_thinking_claude.to_csv(\"../exp/preds_LLMs/Claude/Thinking/thinking_claude_class_def_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "71a5f0ea55213998",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:55.614807Z",
     "start_time": "2025-05-18T13:53:55.610572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# profiled_simple_y_pred_claude = []\n",
    "# profiled_simple_thinking_claude = []\n",
    "#\n",
    "# client = anthropic.Anthropic(api_key = os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_profiled_simple_prompt:\n",
    "#     message = client.messages.create(\n",
    "#         model = \"claude-3-7-sonnet-20250219\",\n",
    "#         max_tokens = 20000,\n",
    "#         temperature = 1,\n",
    "#         thinking = {\n",
    "#             \"type\": \"enabled\",\n",
    "#             \"budget_tokens\": 16000\n",
    "#         },\n",
    "#         system = profiled_simple_instruction,\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "#     )\n",
    "#     profiled_simple_y_pred_claude.append(message.content[1].text)\n",
    "#     profiled_simple_thinking_claude.append(message.content[0].thinking)\n",
    "#     print(message.content[1].text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_claude_profiled_simple = end - start\n",
    "# time_claude_profiled_simple_df = pd.DataFrame({\"time\": [time_claude_profiled_simple]})\n",
    "# time_claude_profiled_simple_df.to_csv(\"../exp/times_LLMs/Claude/time_claude_profiled_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_profiled_simple_claude = pd.Series(profiled_simple_y_pred_claude).value_counts()\n",
    "# print(counts_profiled_simple_claude)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# profiled_simple_y_pred_claude_val = [1 if response == \"YES\" else 0 for response in profiled_simple_y_pred_claude]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# profiled_simple_df_claude = pd.DataFrame(profiled_simple_y_pred_claude_val, columns = [\"y_pred\"])\n",
    "# profiled_simple_df_claude.to_csv(\"../exp/preds_LLMs/Claude/y_pred_claude_profiled_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# profiled_simple_prompt_df_thinking_claude = pd.DataFrame(profiled_simple_thinking_claude, columns = [\"thinking\"])\n",
    "# profiled_simple_prompt_df_thinking_claude.to_csv(\"../exp/preds_LLMs/Claude/Thinking/thinking_claude_profiled_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "a1e5ce97442023ea",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:55.938967Z",
     "start_time": "2025-05-18T13:53:55.934984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# few_shot_y_pred_claude = []\n",
    "# few_shot_thinking_claude = []\n",
    "#\n",
    "# client = anthropic.Anthropic(api_key = os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_few_shot_prompt:\n",
    "#     message = client.messages.create(\n",
    "#         model = \"claude-3-7-sonnet-20250219\",\n",
    "#         max_tokens = 20000,\n",
    "#         temperature = 1,\n",
    "#         thinking = {\n",
    "#             \"type\": \"enabled\",\n",
    "#             \"budget_tokens\": 16000\n",
    "#         },\n",
    "#         system = few_shot_instruction,\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "#     )\n",
    "#     few_shot_y_pred_claude.append(message.content[1].text)\n",
    "#     few_shot_thinking_claude.append(message.content[0].thinking)\n",
    "#     print(message.content[1].text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_claude_few_shot = end - start\n",
    "# time_claude_few_shot_df = pd.DataFrame({\"time\": [time_claude_few_shot]})\n",
    "# time_claude_few_shot_df.to_csv(\"../exp/times_LLMs/Claude/time_claude_few_shot_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_few_shot_claude = pd.Series(few_shot_y_pred_claude).value_counts()\n",
    "# print(counts_few_shot_claude)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# few_shot_y_pred_claude_val = [1 if response == \"YES\" else 0 for response in few_shot_y_pred_claude]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# few_shot_df_claude = pd.DataFrame(few_shot_y_pred_claude_val, columns = [\"y_pred\"])\n",
    "# few_shot_df_claude.to_csv(\"../exp/preds_LLMs/Claude/y_pred_claude_few_shot_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# few_shot_prompt_df_thinking_claude = pd.DataFrame(few_shot_thinking_claude, columns = [\"thinking\"])\n",
    "# few_shot_prompt_df_thinking_claude.to_csv(\"../exp/preds_LLMs/Claude/Thinking/thinking_claude_few_shot_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "c7bd23ac0b2904bb",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:56.284349Z",
     "start_time": "2025-05-18T13:53:56.280388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# vignette_y_pred_claude = []\n",
    "# vignette_thinking_claude = []\n",
    "#\n",
    "# client = anthropic.Anthropic(api_key = os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_vignette_prompt:\n",
    "#     message = client.messages.create(\n",
    "#         model = \"claude-3-7-sonnet-20250219\",\n",
    "#         max_tokens = 20000,\n",
    "#         temperature = 1,\n",
    "#         thinking = {\n",
    "#             \"type\": \"enabled\",\n",
    "#             \"budget_tokens\": 16000\n",
    "#         },\n",
    "#         system = vignette_instruction,\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "#     )\n",
    "#     vignette_y_pred_claude.append(message.content[1].text)\n",
    "#     vignette_thinking_claude.append(message.content[0].thinking)\n",
    "#     print(message.content[1].text)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_claude_vignette = end - start\n",
    "# time_claude_vignette_df = pd.DataFrame({\"time\": [time_claude_vignette]})\n",
    "# time_claude_vignette_df.to_csv(\"../exp/times_LLMs/Claude/time_claude_vignette_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_vignette_claude = pd.Series(vignette_y_pred_claude).value_counts()\n",
    "# print(counts_vignette_claude)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# vignette_y_pred_claude_val = [1 if response == \"YES\" else 0 for response in vignette_y_pred_claude]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# vignette_df_claude = pd.DataFrame(vignette_y_pred_claude_val, columns = [\"y_pred\"])\n",
    "# vignette_df_claude.to_csv(\"../exp/preds_LLMs/Claude/y_pred_claude_vignette_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# vignette_prompt_df_thinking_claude = pd.DataFrame(vignette_thinking_claude, columns = [\"thinking\"])\n",
    "# vignette_prompt_df_thinking_claude.to_csv(\"../exp/preds_LLMs/Claude/Thinking/thinking_claude_vignette_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "c052ee81007a6a1f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:54:49.756402Z",
     "start_time": "2025-05-18T13:53:56.620301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# claude_prompt_y_pred_claude = []\n",
    "# claude_prompt_explanation_claude = []\n",
    "# claude_prompt_thinking_claude = []\n",
    "#\n",
    "# client = anthropic.Anthropic(api_key = os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_claude_prompt[:2]:\n",
    "#     message = client.messages.create(\n",
    "#         model = \"claude-3-7-sonnet-20250219\",\n",
    "#         max_tokens = 20000,\n",
    "#         temperature = 1,\n",
    "#         thinking = {\n",
    "#             \"type\": \"enabled\",\n",
    "#             \"budget_tokens\": 16000\n",
    "#         },\n",
    "#         system = claude_instruction,\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "#     )\n",
    "#     try:\n",
    "#         prediction = re.findall(r'Prediction: (.*)', message.content[1].text)[0]\n",
    "#         explanation = re.findall(r'Explanation: (.*)', message.content[1].text)[0]\n",
    "#         claude_prompt_y_pred_claude.append(prediction)\n",
    "#         claude_prompt_explanation_claude.append(explanation)\n",
    "#         claude_prompt_thinking_claude.append(message.content[0].thinking)\n",
    "#         print(prediction)\n",
    "#     except IndexError:\n",
    "#         print(\"IndexError\")\n",
    "#         claude_prompt_y_pred_claude.append(\"IndexError\")\n",
    "#         claude_prompt_explanation_claude.append(\"IndexError\")\n",
    "#         claude_prompt_thinking_claude.append(\"IndexError\")\n",
    "#\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_claude_claude_prompt = end - start\n",
    "# time_claude_claude_prompt_df = pd.DataFrame({\"time\": [time_claude_claude_prompt]})\n",
    "# time_claude_claude_prompt_df.to_csv(\"../exp/times_LLMs/Claude/time_claude_claude_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_claude_prompt_claude = pd.Series(claude_prompt_y_pred_claude).value_counts()\n",
    "# print(counts_claude_prompt_claude)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# claude_prompt_y_pred_claude_val = [1 if response == \"YES\" else 0 for response in claude_prompt_y_pred_claude]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# claude_prompt_df_claude = pd.DataFrame(claude_prompt_y_pred_claude_val, columns = [\"y_pred\"])\n",
    "# claude_prompt_df_claude.to_csv(\"../exp/preds_LLMs/Claude/y_pred_claude_claude_prompt_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# claude_prompt_prompt_df_thinking_claude = pd.DataFrame(claude_prompt_thinking_claude, columns = [\"thinking\"])\n",
    "# claude_prompt_prompt_df_thinking_claude.to_csv(\"../exp/preds_LLMs/Claude/Thinking/thinking_claude_claude_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# claude_prompt_prompt_df_explanation_claude = pd.DataFrame(claude_prompt_explanation_claude, columns = [\"thinking\"])\n",
    "# claude_prompt_prompt_df_explanation_claude.to_csv(\"../exp/preds_LLMs/Claude/Thinking/explanation_claude_claude_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "50df74bd8286714",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n",
      "NO\n",
      "Time taken: 53.0749671459198 seconds\n",
      "NO    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.6 DeepSeek",
   "id": "67c94f3e4d544889"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.6.1 Testing prompting",
   "id": "9aa1e23112271d8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:52:45.716650Z",
     "start_time": "2025-05-18T14:51:56.622630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI(api_key = os.environ.get(\"DeepSeek_API_Key\"), base_url = \"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"deepseek-reasoner\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": simple_instruction},\n",
    "        {\"role\": \"user\", \"content\": X_test_simple_prompt[0]},\n",
    "    ],\n",
    "    stream = False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "72f8f909a923d996",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:53:32.558249Z",
     "start_time": "2025-05-18T14:53:32.553707Z"
    }
   },
   "cell_type": "code",
   "source": "response.choices[0].message.reasoning_content",
   "id": "ba3227e6778f7899",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, let's see. I need to determine if the person develops a psychological disorder between T1 and T2 based on the given data. The answer should be just YES or NO. \\n\\nFirst, looking at the T1 values. The General psychopathology (GSI) at T1 is 0.0172, which is very low. That suggests that at T1, their psychopathology isn't severe. Other factors like stress are 0.44, which is moderate. Positive mental health is slightly negative but close to zero. Social support, self-efficacy, life satisfaction are all positive, but not extremely high. Problem-focused coping is quite high at 1.73, which might be a protective factor. Emotion-focused coping is lower. Anxiety sensitivity and fear of bodily sensations are low to moderate. Dysfunctional attitudes are around 0.27.\\n\\nNow, looking at the changes from T1 to T2. The change in GSI (General psychopathology) is -0.8256, which means it decreased. That's a significant drop. But wait, if GSI decreases, that would imply their psychopathology is getting better, right? So from 0.0172 to 0.0172 -0.8256? Wait, that would make GSI at T2 negative? That doesn't make sense because GSI is a measure that's usually a positive value. Maybe the change is subtracted? Or maybe the scores are standardized? Hmm. Maybe the initial GSI was already very low, and a decrease would mean even lower, but maybe below a certain threshold? Not sure. But the key point is that the change is negative, so improvement.\\n\\nOther changes: Positive mental health decreased by -0.75, which is a big drop. Social support increased by 0.705. General self-efficacy decreased slightly. Life satisfaction increased a bit. Anxiety sensitivity and fear of bodily sensations both decreased significantly (around -0.86 and -0.84). Dysfunctional attitudes increased by 0.48, which is a notable increase. But GSI decreased a lot.\\n\\nSo, the main factors that might contribute to developing a disorder: increased dysfunctional attitudes, decreased positive mental health. However, GSI is going down, which suggests less psychopathology. Stress isn't mentioned in the change data, so we don't know how that changed. The initial stress was 0.44, but without knowing the change, maybe it stayed the same or increased?\\n\\nBut the GSI is the main indicator of general psychopathology. If that's decreasing, even with some negative changes in other areas, the overall trend is improvement. However, the question is whether they developed a disorder between T1 and T2. At T1, their GSI was very low, almost non-existent. Even with a decrease (which might not be possible if it's already low), maybe the T2 GSI is even lower. But developing a disorder would require an increase in symptoms. Wait, the change in GSI is negative, so T2 GSI is T1 GSI plus the change. So 0.0172 -0.8256 = negative? That's confusing. Maybe the data is standardized, so negative values indicate below the mean. But if GSI is a measure where higher is worse, then a decrease would be improvement. If at T1, their GSI was already low, and it's decreasing further, that's better. But how does that relate to developing a disorder? They would need an increase. \\n\\nWait, maybe the problem is that even if GSI is decreasing, other factors like dysfunctional attitudes increasing could contribute. Dysfunctional attitudes are a risk factor for depression, for example. But their GSI is going down. Positive mental health is decreasing, which is bad, but social support is increasing. Stress level at T1 was moderate. So conflicting factors. However, the key indicator for a psychological disorder is likely the GSI. If that's going down, even with some negative changes elsewhere, the person is less likely to have developed a disorder. Unless the other factors outweigh. But I'm not sure. The answer might be NO because the GSI decreased, indicating improvement, despite some negative changes. However, the increase in dysfunctional attitudes is a concern. But without knowing the thresholds for these variables, it's hard. Since the question is likely based on the GSI change, which is the main psychopathology measure, and it's improving, the answer is NO.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.6.2 Prompting with DeepSeek Reasoning R1",
   "id": "805d4589490aa7c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:54.945425Z",
     "start_time": "2025-05-18T13:53:54.940351Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 24,
   "source": [
    "# simple_prompt_y_pred_deeps = []\n",
    "# simple_prompt_thinking_deeps = []\n",
    "#\n",
    "# client = OpenAI(api_key = os.environ.get(\"DeepSeek_API_Key\"), base_url = \"https://api.deepseek.com\")\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_simple_prompt:\n",
    "#     response = client.chat.completions.create(\n",
    "#         model = \"deepseek-reasoner\",\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": simple_instruction},\n",
    "#             {\"role\": \"user\", \"content\": prompt},\n",
    "#         ],\n",
    "#         stream = False\n",
    "#     )\n",
    "#     simple_prompt_y_pred_deeps.append(response.choices[0].message.content)\n",
    "#     simple_prompt_thinking_deeps.append(response.choices[0].message.reasoning_content)\n",
    "#     print(response.choices[0].message.content)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_deeps_simple_prompt = end - start\n",
    "# time_deeps_simple_prompt_df = pd.DataFrame({\"time\": [time_deeps_simple_prompt]})\n",
    "# time_deeps_simple_prompt_df.to_csv(\"../exp/times_LLMs/DeepSeek/time_deeps_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_simple_deeps = pd.Series(simple_prompt_y_pred_deeps).value_counts()\n",
    "# print(counts_simple_deeps)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# simple_prompt_y_pred_deeps = [1 if response == \"YES\" else 0 if response == \"NO\" else np.nan for response in simple_prompt_y_pred_deeps]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# simple_prompt_df_deeps = pd.DataFrame(simple_prompt_y_pred_deeps, columns = [\"y_pred\"])\n",
    "# simple_prompt_df_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/y_pred_deeps_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# simple_prompt_df_thinking_deeps = pd.DataFrame(simple_prompt_thinking_deeps, columns = [\"thinking\"])\n",
    "# simple_prompt_df_thinking_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/Thinking/thinking_deeps_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "c4e8afcb4089cc18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:55.280539Z",
     "start_time": "2025-05-18T13:53:55.276871Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 25,
   "source": [
    "# class_def_y_pred_deeps = []\n",
    "# class_def_thinking_deeps = []\n",
    "#\n",
    "# client = OpenAI(api_key = os.environ.get(\"DeepSeek_API_Key\"), base_url = \"https://api.deepseek.com\")\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_class_definitions_prompt:\n",
    "#     response = client.chat.completions.create(\n",
    "#         model = \"deepseek-reasoner\",\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": simple_instruction},\n",
    "#             {\"role\": \"user\", \"content\": prompt},\n",
    "#         ],\n",
    "#         stream = False\n",
    "#     )\n",
    "#     class_def_y_pred_deeps.append(response.choices[0].message.content)\n",
    "#     class_def_thinking_deeps.append(response.choices[0].message.reasoning_content)\n",
    "#     print(response.choices[0].message.content)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_deeps_class_definitions = end - start\n",
    "# time_deeps_class_definitions_df = pd.DataFrame({\"time\": [time_deeps_class_definitions]})\n",
    "# time_deeps_class_definitions_df.to_csv(\"../exp/times_LLMs/DeepSeek/time_deeps_class_definitions_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_class_def_deeps = pd.Series(class_def_y_pred_deeps).value_counts()\n",
    "# print(counts_class_def_deeps)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# class_def_y_pred_deeps = [1 if response == \"YES\" else 0 for response in class_def_y_pred_deeps]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# class_def_df_deeps = pd.DataFrame(class_def_y_pred_deeps, columns = [\"y_pred\"])\n",
    "# class_def_df_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/y_pred_deeps_class_definitions_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# class_def_prompt_df_thinking_deeps = pd.DataFrame(class_def_thinking_deeps, columns = [\"thinking\"])\n",
    "# class_def_prompt_df_thinking_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/Thinking/thinking_deeps_class_def_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "9f90a9516821da3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:55.614807Z",
     "start_time": "2025-05-18T13:53:55.610572Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 26,
   "source": [
    "# profiled_simple_y_pred_deeps = []\n",
    "# profiled_simple_thinking_deeps = []\n",
    "#\n",
    "# client = OpenAI(api_key = os.environ.get(\"DeepSeek_API_Key\"), base_url = \"https://api.deepseek.com\")\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_profiled_simple_prompt:\n",
    "#     response = client.chat.completions.create(\n",
    "#         model = \"deepseek-reasoner\",\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": simple_instruction},\n",
    "#             {\"role\": \"user\", \"content\": prompt},\n",
    "#         ],\n",
    "#         stream = False\n",
    "#     )\n",
    "#     profiled_simple_y_pred_deeps.append(response.choices[0].message.content)\n",
    "#     profiled_simple_thinking_deeps.append(response.choices[0].message.reasoning_content)\n",
    "#     print(response.choices[0].message.content)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_deeps_profiled_simple = end - start\n",
    "# time_deeps_profiled_simple_df = pd.DataFrame({\"time\": [time_deeps_profiled_simple]})\n",
    "# time_deeps_profiled_simple_df.to_csv(\"../exp/times_LLMs/DeepSeek/time_deeps_profiled_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_profiled_simple_deeps = pd.Series(profiled_simple_y_pred_deeps).value_counts()\n",
    "# print(counts_profiled_simple_deeps)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# profiled_simple_y_pred_deeps_val = [1 if response == \"YES\" else 0 for response in profiled_simple_y_pred_deeps]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# profiled_simple_df_deeps = pd.DataFrame(profiled_simple_y_pred_deeps_val, columns = [\"y_pred\"])\n",
    "# profiled_simple_df_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/y_pred_deeps_profiled_simple_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# profiled_simple_prompt_df_thinking_deeps = pd.DataFrame(profiled_simple_thinking_deeps, columns = [\"thinking\"])\n",
    "# profiled_simple_prompt_df_thinking_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/Thinking/thinking_deeps_profiled_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "bdac2e6ac9872c91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:55.938967Z",
     "start_time": "2025-05-18T13:53:55.934984Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 27,
   "source": [
    "# few_shot_y_pred_deeps = []\n",
    "# few_shot_thinking_deeps = []\n",
    "#\n",
    "# client = OpenAI(api_key = os.environ.get(\"DeepSeek_API_Key\"), base_url = \"https://api.deepseek.com\")\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_few_shot_prompt:\n",
    "#     response = client.chat.completions.create(\n",
    "#         model = \"deepseek-reasoner\",\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": simple_instruction},\n",
    "#             {\"role\": \"user\", \"content\": prompt},\n",
    "#         ],\n",
    "#         stream = False\n",
    "#     )\n",
    "#     few_shot_y_pred_deeps.append(response.choices[0].message.content)\n",
    "#     few_shot_thinking_deeps.append(response.choices[0].message.reasoning_content)\n",
    "#     print(response.choices[0].message.content)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_deeps_few_shot = end - start\n",
    "# time_deeps_few_shot_df = pd.DataFrame({\"time\": [time_deeps_few_shot]})\n",
    "# time_deeps_few_shot_df.to_csv(\"../exp/times_LLMs/DeepSeek/time_deeps_few_shot_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_few_shot_deeps = pd.Series(few_shot_y_pred_deeps).value_counts()\n",
    "# print(counts_few_shot_deeps)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# few_shot_y_pred_deeps_val = [1 if response == \"YES\" else 0 for response in few_shot_y_pred_deeps]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# few_shot_df_deeps = pd.DataFrame(few_shot_y_pred_deeps_val, columns = [\"y_pred\"])\n",
    "# few_shot_df_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/y_pred_deeps_few_shot_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# few_shot_prompt_df_thinking_deeps = pd.DataFrame(few_shot_thinking_deeps, columns = [\"thinking\"])\n",
    "# few_shot_prompt_df_thinking_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/Thinking/thinking_deeps_few_shot_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "dc9a2fbf596bb1b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:53:56.284349Z",
     "start_time": "2025-05-18T13:53:56.280388Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 28,
   "source": [
    "# vignette_y_pred_deeps = []\n",
    "# vignette_thinking_deeps = []\n",
    "#\n",
    "# client = OpenAI(api_key = os.environ.get(\"DeepSeek_API_Key\"), base_url = \"https://api.deepseek.com\")\n",
    "#\n",
    "# # measure time in seconds\n",
    "# start = time.time()\n",
    "#\n",
    "# # iterate over the test set and save the response for each prompt in an array\n",
    "# for prompt in X_test_vignette_prompt:\n",
    "#     response = client.chat.completions.create(\n",
    "#         model = \"deepseek-reasoner\",\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": simple_instruction},\n",
    "#             {\"role\": \"user\", \"content\": prompt},\n",
    "#         ],\n",
    "#         stream = False\n",
    "#     )\n",
    "#     vignette_y_pred_deeps.append(response.choices[0].message.content)\n",
    "#     vignette_thinking_deeps.append(response.choices[0].message.reasoning_content)\n",
    "#     print(response.choices[0].message.content)\n",
    "#\n",
    "# end = time.time()\n",
    "# print(f\"Time taken: {end - start} seconds\")\n",
    "# time_deeps_vignette = end - start\n",
    "# time_deeps_vignette_df = pd.DataFrame({\"time\": [time_deeps_vignette]})\n",
    "# time_deeps_vignette_df.to_csv(\"../exp/times_LLMs/DeepSeek/time_deeps_vignette_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# # value counts for array\n",
    "# counts_vignette_deeps = pd.Series(vignette_y_pred_deeps).value_counts()\n",
    "# print(counts_vignette_deeps)\n",
    "#\n",
    "# # convert YES to 1 and NO to 0\n",
    "# vignette_y_pred_deeps_val = [1 if response == \"YES\" else 0 for response in vignette_y_pred_deeps]\n",
    "#\n",
    "# # save the array to a csv file\n",
    "# vignette_df_deeps = pd.DataFrame(vignette_y_pred_deeps_val, columns = [\"y_pred\"])\n",
    "# vignette_df_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/y_pred_deeps_vignette_prompt.csv\", sep = \",\", index = False)\n",
    "#\n",
    "# vignette_prompt_df_thinking_deeps = pd.DataFrame(vignette_thinking_deeps, columns = [\"thinking\"])\n",
    "# vignette_prompt_df_thinking_deeps.to_csv(\"../exp/preds_LLMs/DeepSeek/Thinking/thinking_deeps_vignette_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "223551e5e99ddca3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5b34a0d70a4c6d00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.7 Grok (xAI)",
   "id": "2de5034f0724ce29"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.7.1 Testing prompting",
   "id": "890c30dbf136a459"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:23:23.609563Z",
     "start_time": "2025-05-18T15:23:07.546284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# client = OpenAI(\n",
    "#     api_key = os.environ.get(\"XAI_API_KEY\"),\n",
    "#     base_url = \"https://api.x.ai/v1\",\n",
    "# )\n",
    "#\n",
    "# completion = client.chat.completions.create(\n",
    "#     model = \"grok-3-beta\",\n",
    "#     # model = \"grok-3-mini-beta\",\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": simple_instruction},\n",
    "#         {\"role\": \"user\", \"content\": X_test_simple_prompt[0]},\n",
    "#     ],\n",
    "#     # reasoning_effort = \"high\"\n",
    "# )\n",
    "# print(completion.choices[0].message)"
   ],
   "id": "85c8051c51bdfa03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='NO', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning_content='First, the user asks me to respond only with YES or NO to whether the person develops a psychological disorder between T1 and T2.\\n\\nI have data points at T1 and changes from T1 to T2 for various psychological measures.\\n\\nKey data includes:\\n\\n- T1 General psychopathology: Global Severity Index (GSI): 0.0172227087467131\\n\\n- Change in General psychopathology: GSI (T2-T1): -0.8256637821414634\\n\\nGSI is a measure of general psychopathology. A higher GSI typically indicates more severe symptoms.\\n\\nAt T1, GSI is very low (0.0172), suggesting low psychopathology.\\n\\nThe change from T1 to T2 is -0.8257, which is negative. This means the GSI decreased from T1 to T2. So, at T2, the GSI is even lower.\\n\\nA decrease in GSI suggests an improvement in mental health, not the development of a disorder.\\n\\nThe question is about developing a psychological disorder. If GSI decreases, it\\'s unlikely that a disorder developed.\\n\\nI should check if there\\'s any other indicator. The data includes changes in other variables like anxiety sensitivity, fear of bodily sensations, etc., which decreased, and some increased like dysfunctional attitudes.\\n\\nBut the primary measure for psychopathology is the GSI. A negative change indicates reduction in symptoms.\\n\\nTo develop a disorder, we might expect an increase in GSI or other pathological measures.\\n\\nHere, change in GSI is negative, meaning less psychopathology.\\n\\nAlso, change in anxiety sensitivity and fear of bodily sensations are both negative and large in magnitude, suggesting improvement.\\n\\nChange in dysfunctional attitudes is positive (increase), which might be a risk factor, but GSI is the direct measure.\\n\\nMoreover, positive mental health changed negatively (-0.752), which could indicate worsening, but GSI is specifically for psychopathology.\\n\\nThe GSI change is strongly negative, indicating no development of disorder.\\n\\nPerhaps I need to know the absolute values at T2.\\n\\nT1 GSI is 0.0172, change is -0.8257, so T2 GSI = T1 GSI + change = 0.0172 - 0.8257 = -0.8085. A negative GSI? That might not make sense if GSI is a score that can\\'t be negative, but in the data, it\\'s given as a change, so perhaps it\\'s scaled or possible.\\n\\nAssuming the scale allows it, a very low or negative value would still indicate low psychopathology.\\n\\nIn standard GSI, scores are usually non-negative, but perhaps this is standardized or z-scored.\\n\\nLooking back at T1 GSI: 0.0172, which is very low, and change is large negative, so T2 is even lower.\\n\\nThis suggests improvement, not development of a disorder.\\n\\nOther changes: positive mental health decreased, but GSI improved.\\n\\nThe question is about developing a psychological disorder, and GSI is a direct measure.\\n\\nI think based on this, the answer should be NO.\\n\\nBut let me make sure there\\'s no trick. The user said \"Respond only with YES or NO\", so I need to be concise.\\n\\nPerhaps I need to consider if any disorder developed despite GSI decrease, but that seems unlikely with the data provided.\\n\\nMaybe the changes in other variables indicate risk, but GSI is the outcome measure.\\n\\nIn the data, there\\'s \"General psychopathology: GSI\" and its change.\\n\\nI think it\\'s safe to say NO.')\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:23:23.951328Z",
     "start_time": "2025-05-18T15:23:23.945858Z"
    }
   },
   "cell_type": "code",
   "source": "# completion.choices[0].message.content",
   "id": "def9ffd295fcac01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NO'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.7.2 Prompting with Grok 3 Beta",
   "id": "96ac301e06013696"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:36:02.089806Z",
     "start_time": "2025-05-18T15:36:00.571542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simple_prompt_y_pred_grok = []\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ.get(\"XAI_API_KEY\"),\n",
    "    base_url = \"https://api.x.ai/v1\",\n",
    ")\n",
    "\n",
    "# measure time in seconds\n",
    "start = time.time()\n",
    "\n",
    "# iterate over the test set and save the response for each prompt in an array\n",
    "for prompt in X_test_simple_prompt:\n",
    "    completion = client.chat.completions.create(\n",
    "        model = \"grok-3-beta\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": simple_instruction},\n",
    "            {\"role\": \"user\", \"content\": X_test_simple_prompt[0]},\n",
    "        ],\n",
    "    )\n",
    "    simple_prompt_y_pred_grok.append(completion.choices[0].message.content)\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")\n",
    "time_grok_simple_prompt = end - start\n",
    "time_grok_simple_prompt_df = pd.DataFrame({\"time\": [time_grok_simple_prompt]})\n",
    "time_grok_simple_prompt_df.to_csv(\"../exp/times_LLMs/Grok/time_grok_simple_prompt.csv\", sep = \",\", index = False)\n",
    "\n",
    "# value counts for array\n",
    "counts_simple_grok = pd.Series(simple_prompt_y_pred_grok).value_counts()\n",
    "print(counts_simple_grok)\n",
    "\n",
    "# convert YES to 1 and NO to 0\n",
    "simple_prompt_y_pred_grok = [1 if response == \"YES\" else 0 if response == \"NO\" else np.nan for response in simple_prompt_y_pred_grok]\n",
    "\n",
    "# save the array to a csv file\n",
    "simple_prompt_df_grok = pd.DataFrame(simple_prompt_y_pred_grok, columns = [\"y_pred\"])\n",
    "simple_prompt_df_grok.to_csv(\"../exp/preds_LLMs/Grok/y_pred_grok_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "7b9d68135474d0dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the following person develop a psychological disorder between time point T1 and T2? Data: T1 Positive mental health: -0.0279170753483525, T1 Social support: 0.1421238143169474, T1 General self-efficacy: 0.3649793457412237, T1 Life satisfaction: 0.3372886835461141, T1 Stress: 0.4419361727222826, T1 Problem-focused coping: 1.7319368683783989, T1 Emotion-focused coping: 0.2078300133169115, T1 Anxiety sensitivity: 0.1594156886399411, T1 Fear of bodily sensations: 0.2863750811390516, T1 Dysfunctional attitudes: 0.2750686254386546, T1 General psychopathology: Global Severity Index (GSI): 0.0172227087467131, Education: 2.0, T1 BMI: 1.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): 0.7057099569575698, Change in General self-efficacy (T2-T1): -0.1819798191096402, Change in Life satisfaction (T2-T1): 0.1407378746091848, Change in Anxiety sensitivity (T2-T1): -0.8617238998696288, Change in Fear of bodily sensations (T2-T1): -0.846980042266938, Change in Dysfunctional attitudes (T2-T1): 0.4849021865236002, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -0.8256637821414634\n",
      "NO\n",
      "Does the following person develop a psychological disorder between time point T1 and T2? Data: T1 Positive mental health: -0.0279170753483525, T1 Social support: 1.0790451808002794, T1 General self-efficacy: -2.3549374763869046, T1 Life satisfaction: -0.471818725223128, T1 Stress: 0.0419806820921755, T1 Problem-focused coping: 0.8532782878883876, T1 Emotion-focused coping: -0.8456281474585625, T1 Anxiety sensitivity: 0.5557512543954795, T1 Fear of bodily sensations: 1.241666884265578, T1 Dysfunctional attitudes: -0.2250808121114963, T1 General psychopathology: Global Severity Index (GSI): 1.5062628203345918, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): -0.460474567131092, Change in General self-efficacy (T2-T1): 1.7532147220525784, Change in Life satisfaction (T2-T1): 0.3167090300485398, Change in Anxiety sensitivity (T2-T1): 0.5185167790561809, Change in Fear of bodily sensations (T2-T1): 1.781472184716851, Change in Dysfunctional attitudes (T2-T1): 0.8097267435207866, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -1.09104984935167\n",
      "NO\n",
      "Time taken: 1.4973251819610596 seconds\n",
      "NO    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:35:46.004670Z",
     "start_time": "2025-05-18T15:35:34.557395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_def_y_pred_grok = []\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ.get(\"XAI_API_KEY\"),\n",
    "    base_url = \"https://api.x.ai/v1\",\n",
    ")\n",
    "\n",
    "# measure time in seconds\n",
    "start = time.time()\n",
    "\n",
    "# iterate over the test set and save the response for each prompt in an array\n",
    "for prompt in X_test_class_definitions_prompt:\n",
    "    completion = client.chat.completions.create(\n",
    "        model = \"grok-3-beta\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": class_definitions_instruction},\n",
    "            {\"role\": \"user\", \"content\": X_test_simple_prompt[0]},\n",
    "        ],\n",
    "    )\n",
    "    class_def_y_pred_grok.append(completion.choices[0].message.content)\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")\n",
    "time_grok_class_definitions = end - start\n",
    "time_grok_class_definitions_df = pd.DataFrame({\"time\": [time_grok_class_definitions]})\n",
    "time_grok_class_definitions_df.to_csv(\"../exp/times_LLMs/Grok/time_grok_class_definitions_prompt.csv\", sep = \",\", index = False)\n",
    "\n",
    "# value counts for array\n",
    "counts_class_def_grok = pd.Series(class_def_y_pred_grok).value_counts()\n",
    "print(counts_class_def_grok)\n",
    "\n",
    "# convert YES to 1 and NO to 0\n",
    "class_def_y_pred_grok = [1 if response == \"YES\" else 0 for response in class_def_y_pred_grok]\n",
    "\n",
    "# save the array to a csv file\n",
    "class_def_df_grok = pd.DataFrame(class_def_y_pred_grok, columns = [\"y_pred\"])\n",
    "class_def_df_grok.to_csv(\"../exp/preds_LLMs/Grok/y_pred_grok_class_definitions_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "6fda4258177ebdd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following data, classify whether this person develops a psychological disorder between T1 and T2 according to the instructions provided and data measured by F-DIPS structural interviews. Respond with YES or NO. Instructions: NO: The person did not develop any new psychological disorder between T1 and T2. This means they were either healthy at both time points, had an ongoing disorder across both time points, or had already recovered from a previous disorder. YES: The person was psychologically healthy at T1 but developed a psychological disorder at T2. Does the following person develop a psychological disorder between time point T1 and T2? Data: T1 Positive mental health: -0.0279170753483525, T1 Social support: 0.1421238143169474, T1 General self-efficacy: 0.3649793457412237, T1 Life satisfaction: 0.3372886835461141, T1 Stress: 0.4419361727222826, T1 Problem-focused coping: 1.7319368683783989, T1 Emotion-focused coping: 0.2078300133169115, T1 Anxiety sensitivity: 0.1594156886399411, T1 Fear of bodily sensations: 0.2863750811390516, T1 Dysfunctional attitudes: 0.2750686254386546, T1 General psychopathology: Global Severity Index (GSI): 0.0172227087467131, Education: 2.0, T1 BMI: 1.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): 0.7057099569575698, Change in General self-efficacy (T2-T1): -0.1819798191096402, Change in Life satisfaction (T2-T1): 0.1407378746091848, Change in Anxiety sensitivity (T2-T1): -0.8617238998696288, Change in Fear of bodily sensations (T2-T1): -0.846980042266938, Change in Dysfunctional attitudes (T2-T1): 0.4849021865236002, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -0.8256637821414634\n",
      "NO\n",
      "Given the following data, classify whether this person develops a psychological disorder between T1 and T2 according to the instructions provided and data measured by F-DIPS structural interviews. Respond with YES or NO. Instructions: NO: The person did not develop any new psychological disorder between T1 and T2. This means they were either healthy at both time points, had an ongoing disorder across both time points, or had already recovered from a previous disorder. YES: The person was psychologically healthy at T1 but developed a psychological disorder at T2. Does the following person develop a psychological disorder between time point T1 and T2? Data: T1 Positive mental health: -0.0279170753483525, T1 Social support: 1.0790451808002794, T1 General self-efficacy: -2.3549374763869046, T1 Life satisfaction: -0.471818725223128, T1 Stress: 0.0419806820921755, T1 Problem-focused coping: 0.8532782878883876, T1 Emotion-focused coping: -0.8456281474585625, T1 Anxiety sensitivity: 0.5557512543954795, T1 Fear of bodily sensations: 1.241666884265578, T1 Dysfunctional attitudes: -0.2250808121114963, T1 General psychopathology: Global Severity Index (GSI): 1.5062628203345918, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): -0.460474567131092, Change in General self-efficacy (T2-T1): 1.7532147220525784, Change in Life satisfaction (T2-T1): 0.3167090300485398, Change in Anxiety sensitivity (T2-T1): 0.5185167790561809, Change in Fear of bodily sensations (T2-T1): 1.781472184716851, Change in Dysfunctional attitudes (T2-T1): 0.8097267435207866, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -1.09104984935167\n",
      "NO\n",
      "Time taken: 11.4238440990448 seconds\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:37:08.687474Z",
     "start_time": "2025-05-18T15:36:57.124219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "profiled_simple_y_pred_grok = []\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ.get(\"XAI_API_KEY\"),\n",
    "    base_url = \"https://api.x.ai/v1\",\n",
    ")\n",
    "\n",
    "# measure time in seconds\n",
    "start = time.time()\n",
    "\n",
    "# iterate over the test set and save the response for each prompt in an array\n",
    "for prompt in X_test_profiled_simple_prompt:\n",
    "    completion = client.chat.completions.create(\n",
    "        model = \"grok-3-beta\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": profiled_simple_instruction},\n",
    "            {\"role\": \"user\", \"content\": X_test_simple_prompt[0]},\n",
    "        ],\n",
    "    )\n",
    "    profiled_simple_y_pred_grok.append(completion.choices[0].message.content)\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")\n",
    "time_grok_profiled_simple = end - start\n",
    "time_grok_profiled_simple_df = pd.DataFrame({\"time\": [time_grok_profiled_simple]})\n",
    "time_grok_profiled_simple_df.to_csv(\"../exp/times_LLMs/Grok/time_grok_profiled_simple_prompt.csv\", sep = \",\", index = False)\n",
    "\n",
    "# value counts for array\n",
    "counts_profiled_simple_grok = pd.Series(profiled_simple_y_pred_grok).value_counts()\n",
    "print(counts_profiled_simple_grok)\n",
    "\n",
    "# convert YES to 1 and NO to 0\n",
    "profiled_simple_y_pred_grok_val = [1 if response == \"YES\" else 0 for response in profiled_simple_y_pred_grok]\n",
    "\n",
    "# save the array to a csv file\n",
    "profiled_simple_df_grok = pd.DataFrame(profiled_simple_y_pred_grok_val, columns = [\"y_pred\"])\n",
    "profiled_simple_df_grok.to_csv(\"../exp/preds_LLMs/Grok/y_pred_grok_profiled_simple_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "27d9d12f57eaa20a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in clinical psychology and mental health diagnostics. You are trained to analyze longitudinal data to assess whether a person develops a psychological disorder over time. You know how to analyze data measured with F-DIPS structural interviews at two time points T1 and T2. Does the following person develop a psychological disorder between time point T1 and T2? Data: T1 Positive mental health: -0.0279170753483525, T1 Social support: 0.1421238143169474, T1 General self-efficacy: 0.3649793457412237, T1 Life satisfaction: 0.3372886835461141, T1 Stress: 0.4419361727222826, T1 Problem-focused coping: 1.7319368683783989, T1 Emotion-focused coping: 0.2078300133169115, T1 Anxiety sensitivity: 0.1594156886399411, T1 Fear of bodily sensations: 0.2863750811390516, T1 Dysfunctional attitudes: 0.2750686254386546, T1 General psychopathology: Global Severity Index (GSI): 0.0172227087467131, Education: 2.0, T1 BMI: 1.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): 0.7057099569575698, Change in General self-efficacy (T2-T1): -0.1819798191096402, Change in Life satisfaction (T2-T1): 0.1407378746091848, Change in Anxiety sensitivity (T2-T1): -0.8617238998696288, Change in Fear of bodily sensations (T2-T1): -0.846980042266938, Change in Dysfunctional attitudes (T2-T1): 0.4849021865236002, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -0.8256637821414634\n",
      "NO\n",
      "You are an expert in clinical psychology and mental health diagnostics. You are trained to analyze longitudinal data to assess whether a person develops a psychological disorder over time. You know how to analyze data measured with F-DIPS structural interviews at two time points T1 and T2. Does the following person develop a psychological disorder between time point T1 and T2? Data: T1 Positive mental health: -0.0279170753483525, T1 Social support: 1.0790451808002794, T1 General self-efficacy: -2.3549374763869046, T1 Life satisfaction: -0.471818725223128, T1 Stress: 0.0419806820921755, T1 Problem-focused coping: 0.8532782878883876, T1 Emotion-focused coping: -0.8456281474585625, T1 Anxiety sensitivity: 0.5557512543954795, T1 Fear of bodily sensations: 1.241666884265578, T1 Dysfunctional attitudes: -0.2250808121114963, T1 General psychopathology: Global Severity Index (GSI): 1.5062628203345918, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): -0.460474567131092, Change in General self-efficacy (T2-T1): 1.7532147220525784, Change in Life satisfaction (T2-T1): 0.3167090300485398, Change in Anxiety sensitivity (T2-T1): 0.5185167790561809, Change in Fear of bodily sensations (T2-T1): 1.781472184716851, Change in Dysfunctional attitudes (T2-T1): 0.8097267435207866, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -1.09104984935167\n",
      "NO\n",
      "Time taken: 11.54093623161316 seconds\n",
      "NO    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:37:41.630485Z",
     "start_time": "2025-05-18T15:37:40.542722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "few_shot_y_pred_grok = []\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ.get(\"XAI_API_KEY\"),\n",
    "    base_url = \"https://api.x.ai/v1\",\n",
    ")\n",
    "\n",
    "# measure time in seconds\n",
    "start = time.time()\n",
    "\n",
    "# iterate over the test set and save the response for each prompt in an array\n",
    "for prompt in X_test_few_shot_prompt:\n",
    "    completion = client.chat.completions.create(\n",
    "        model = \"grok-3-beta\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": few_shot_instruction},\n",
    "            {\"role\": \"user\", \"content\": X_test_simple_prompt[0]},\n",
    "        ],\n",
    "    )\n",
    "    few_shot_y_pred_grok.append(completion.choices[0].message.content)\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")\n",
    "time_grok_few_shot = end - start\n",
    "time_grok_few_shot_df = pd.DataFrame({\"time\": [time_grok_few_shot]})\n",
    "time_grok_few_shot_df.to_csv(\"../exp/times_LLMs/Grok/time_grok_few_shot_prompt.csv\", sep = \",\", index = False)\n",
    "\n",
    "# value counts for array\n",
    "counts_few_shot_grok = pd.Series(few_shot_y_pred_grok).value_counts()\n",
    "print(counts_few_shot_grok)\n",
    "\n",
    "# convert YES to 1 and NO to 0\n",
    "few_shot_y_pred_grok_val = [1 if response == \"YES\" else 0 for response in few_shot_y_pred_grok]\n",
    "\n",
    "# save the array to a csv file\n",
    "few_shot_df_grok = pd.DataFrame(few_shot_y_pred_grok_val, columns = [\"y_pred\"])\n",
    "few_shot_df_grok.to_csv(\"../exp/preds_LLMs/Grok/y_pred_grok_few_shot_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "9f8614647bda3e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please refer to the following examples of correctly classified data points with 'Total mental disorders incidence point prevalence' being the true classification: ['Example 1: T1 Positive mental health: -0.0279170753483525, T1 Social support: -0.167356999046327, T1 General self-efficacy: -0.5416595949681524, T1 Life satisfaction: -0.471818725223128, T1 Stress: 0.241958427407229, T1 Problem-focused coping: 0.8532782878883876, T1 Emotion-focused coping: 0.2078300133169115, T1 Anxiety sensitivity: 0.6878631096473256, T1 Fear of bodily sensations: 0.3819042614516962, T1 Dysfunctional attitudes: -0.2667599319073422, T1 General psychopathology: Global Severity Index (GSI): -0.2733217032704306, Education: 2.0, T1 BMI: 1.0, Socioeconomic status: 1.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): 0.8692924015129987, Change in General self-efficacy (T2-T1): -0.1819798191096402, Change in Life satisfaction (T2-T1): 0.6686513409272499, Change in Anxiety sensitivity (T2-T1): -1.137772035654791, Change in Fear of bodily sensations (T2-T1): -0.8469800422669385, Change in Dysfunctional attitudes (T2-T1): 0.97213902201938, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -0.3833536701244625, Total mental disorders incidence point prevalence: 1.0', 'Example 2: T1 Positive mental health: 0.9385642092467285, T1 Social support: 0.7229302722726627, T1 General self-efficacy: 0.3649793457412237, T1 Life satisfaction: 0.4991101652999784, T1 Stress: 0.241958427407229, T1 Problem-focused coping: 1.5562051522803964, T1 Emotion-focused coping: 1.7474996329118353, T1 Anxiety sensitivity: -0.1048080218637509, T1 Fear of bodily sensations: 1.5282544252035275, T1 Dysfunctional attitudes: 0.6501807036012678, T1 General psychopathology: Global Severity Index (GSI): 0.1624949147552884, Education: 2.0, T1 BMI: 1.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): 0.0935950031373072, Change in General self-efficacy (T2-T1): 0.0944765439135338, Change in Life satisfaction (T2-T1): 0.1407378746091641, Change in Anxiety sensitivity (T2-T1): -0.3096276282993049, Change in Fear of bodily sensations (T2-T1): -1.236380372190466, Change in Dysfunctional attitudes (T2-T1): -0.0023346489721794, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -0.6045087261329618, Total mental disorders incidence point prevalence: 1.0', 'Example 3: T1 Positive mental health: 0.9385642092467285, T1 Social support: 0.8119589994045722, T1 General self-efficacy: 0.3649793457412237, T1 Life satisfaction: 0.8227531288076683, T1 Stress: -0.557952553852985, T1 Problem-focused coping: 1.204741720084392, T1 Emotion-focused coping: -0.3594166886391129, T1 Anxiety sensitivity: 0.5557512543954795, T1 Fear of bodily sensations: 0.3819042614516962, T1 Dysfunctional attitudes: -0.2667599319073422, T1 General psychopathology: Global Severity Index (GSI): 0.6542168480146436, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -1.2686339879073294, Change in Social support (T2-T1): 0.0935950031373072, Change in General self-efficacy (T2-T1): -0.1819798191096402, Change in Life satisfaction (T2-T1): 0.4926801854879145, Change in Anxiety sensitivity (T2-T1): -0.1716035604067239, Change in Fear of bodily sensations (T2-T1): -0.4575797123434105, Change in Dysfunctional attitudes (T2-T1): -0.0023346489721794, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -1.0706737655396472, Total mental disorders incidence point prevalence: 0.0', 'Example 4: T1 Positive mental health: 0.4553235669491879, T1 Social support: 0.3668153637450668, T1 General self-efficacy: 0.3649793457412237, T1 Life satisfaction: 0.0136457200384251, T1 Stress: -0.7579302991680386, T1 Problem-focused coping: 1.4683392942313953, T1 Emotion-focused coping: 0.3699004995900614, T1 Anxiety sensitivity: 0.2915275438917872, T1 Fear of bodily sensations: 0.5729626220770014, T1 Dysfunctional attitudes: 1.066971901559727, T1 General psychopathology: Global Severity Index (GSI): 0.2869556530491485, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -1.2686339879073294, Change in Social support (T2-T1): -0.5712884811847251, Change in General self-efficacy (T2-T1): -0.1819798191096402, Change in Life satisfaction (T2-T1): 0.1407378746091632, Change in Anxiety sensitivity (T2-T1): -0.4476516961918859, Change in Fear of bodily sensations (T2-T1): -0.554929794824284, Change in Dysfunctional attitudes (T2-T1): 0.1600776295264137, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): 0.7035364590678871, Total mental disorders incidence point prevalence: 0.0', 'Example 5: T1 Positive mental health: 0.4553235669491879, T1 Social support: 0.5448728180088648, T1 General self-efficacy: 1.498278021627944, T1 Life satisfaction: -1.28092613399239, T1 Stress: 0.6419139180373361, T1 Problem-focused coping: 1.4683392942313953, T1 Emotion-focused coping: 0.5319709858632113, T1 Anxiety sensitivity: 0.8199749648991717, T1 Fear of bodily sensations: 0.5729626220770014, T1 Dysfunctional attitudes: 0.7752180629888056, T1 General psychopathology: Global Severity Index (GSI): -0.4185939092790058, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.235399282050399, Change in Social support (T2-T1): -0.0172189109163777, Change in General self-efficacy (T2-T1): -0.4584361821328143, Change in Life satisfaction (T2-T1): -0.3871755917089017, Change in Anxiety sensitivity (T2-T1): -0.9997479677622098, Change in Fear of bodily sensations (T2-T1): -0.7496299597860477, Change in Dysfunctional attitudes (T2-T1): 0.3766273341912047, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): 0.0147254306908422, Total mental disorders incidence point prevalence: 0.0'] Based on the previous example data prompts, classify the following data. Does the following person develop a psychological disorder between time point T1 and T2? Data: T1 Positive mental health: -0.0279170753483525, T1 Social support: 0.1421238143169474, T1 General self-efficacy: 0.3649793457412237, T1 Life satisfaction: 0.3372886835461141, T1 Stress: 0.4419361727222826, T1 Problem-focused coping: 1.7319368683783989, T1 Emotion-focused coping: 0.2078300133169115, T1 Anxiety sensitivity: 0.1594156886399411, T1 Fear of bodily sensations: 0.2863750811390516, T1 Dysfunctional attitudes: 0.2750686254386546, T1 General psychopathology: Global Severity Index (GSI): 0.0172227087467131, Education: 2.0, T1 BMI: 1.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): 0.7057099569575698, Change in General self-efficacy (T2-T1): -0.1819798191096402, Change in Life satisfaction (T2-T1): 0.1407378746091848, Change in Anxiety sensitivity (T2-T1): -0.8617238998696288, Change in Fear of bodily sensations (T2-T1): -0.846980042266938, Change in Dysfunctional attitudes (T2-T1): 0.4849021865236002, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -0.8256637821414634\n",
      "NO\n",
      "Please refer to the following examples of correctly classified data points with 'Total mental disorders incidence point prevalence' being the true classification: ['Example 1: T1 Positive mental health: 0.4553235669491879, T1 Social support: 0.6339015451407742, T1 General self-efficacy: -0.0883401246134643, T1 Life satisfaction: -0.1481757617154391, T1 Stress: 0.241958427407229, T1 Problem-focused coping: 0.413948997643382, T1 Emotion-focused coping: -0.6025224180488378, T1 Anxiety sensitivity: 0.8199749648991717, T1 Fear of bodily sensations: 1.4327252448908838, T1 Dysfunctional attitudes: -0.5585137704782637, T1 General psychopathology: Global Severity Index (GSI): 0.5256754297767214, Education: 3.0, T1 BMI: 2.0, Socioeconomic status: 3.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): -0.1280328249700628, Change in General self-efficacy (T2-T1): 0.3709329069367079, Change in Life satisfaction (T2-T1): 1.196564807245358, Change in Anxiety sensitivity (T2-T1): 0.6565408469487619, Change in Fear of bodily sensations (T2-T1): 0.6132711949462831, Change in Dysfunctional attitudes (T2-T1): -0.2730217798031681, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -0.9141258045448658, Total mental disorders incidence point prevalence: 0.0', 'Example 2: T1 Positive mental health: -0.0279170753483525, T1 Social support: -0.0783282719144384, T1 General self-efficacy: -0.3149998597908083, T1 Life satisfaction: 0.0136457200384251, T1 Stress: -0.157997063222878, T1 Problem-focused coping: 0.9411441459373888, T1 Emotion-focused coping: 0.2078300133169115, T1 Anxiety sensitivity: 0.2915275438917872, T1 Fear of bodily sensations: 0.7640209827023066, T1 Dysfunctional attitudes: 0.6501807036012678, T1 General psychopathology: Global Severity Index (GSI): 1.2785608794559835, Education: 3.0, T1 BMI: 2.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): -0.0172189109163517, Change in General self-efficacy (T2-T1): 0.647389269959882, Change in Life satisfaction (T2-T1): -0.7391179025876333, Change in Anxiety sensitivity (T2-T1): 0.2424686432710189, Change in Fear of bodily sensations (T2-T1): -0.4575797123434101, Change in Dysfunctional attitudes (T2-T1): 0.8638641696869843, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -1.2118154192619288, Total mental disorders incidence point prevalence: 0.0', 'Example 3: T1 Positive mental health: -0.9943983599434336, T1 Social support: 0.3668153637450668, T1 General self-efficacy: -0.9949790653228404, T1 Life satisfaction: 0.4991101652999784, T1 Stress: 0.8418916633523896, T1 Problem-focused coping: 1.204741720084392, T1 Emotion-focused coping: -0.9266633905951376, T1 Anxiety sensitivity: -0.3690317323674431, T1 Fear of bodily sensations: 0.3819042614516962, T1 Dysfunctional attitudes: -0.8085884892533391, T1 General psychopathology: Global Severity Index (GSI): 2.123669695871029, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): 0.281218070878066, Change in Social support (T2-T1): -0.0172189109163777, Change in General self-efficacy (T2-T1): 0.647389269959882, Change in Life satisfaction (T2-T1): 0.3167090300485388, Change in Anxiety sensitivity (T2-T1): 0.6565408469487619, Change in Fear of bodily sensations (T2-T1): 0.1265207825418816, Change in Dysfunctional attitudes (T2-T1): 0.7555893173545889, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -3.1256763646298897, Total mental disorders incidence point prevalence: 0.0', 'Example 4: T1 Positive mental health: -0.0279170753483525, T1 Social support: 0.8119589994045722, T1 General self-efficacy: -0.3149998597908083, T1 Life satisfaction: 0.4843991215041691, T1 Stress: -0.3579748085379315, T1 Problem-focused coping: 0.8532782878883876, T1 Emotion-focused coping: -0.5214871749122628, T1 Anxiety sensitivity: 0.5557512543954795, T1 Fear of bodily sensations: 1.241666884265578, T1 Dysfunctional attitudes: 0.9419345421721892, T1 General psychopathology: Global Severity Index (GSI): 0.0172227087467131, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 1.0, Change in Positive mental health (T2-T1): 0.7978354238065312, Change in Social support (T2-T1): -0.0172189109163777, Change in General self-efficacy (T2-T1): 0.647389269959882, Change in Life satisfaction (T2-T1): -0.0192359030629718, Change in Anxiety sensitivity (T2-T1): 0.5185167790561809, Change in Fear of bodily sensations (T2-T1): 0.41857102998452, Change in Dysfunctional attitudes (T2-T1): -0.1647469274707726, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -0.3391226589227578, Total mental disorders incidence point prevalence: 0.0', 'Example 5: T1 Positive mental health: -0.511157717645893, T1 Social support: 0.9009877265364608, T1 General self-efficacy: -0.3149998597908083, T1 Life satisfaction: -0.9572831704846811, T1 Stress: 0.0419806820921755, T1 Problem-focused coping: 1.204741720084392, T1 Emotion-focused coping: 0.2888652564534865, T1 Anxiety sensitivity: -0.3690317323674431, T1 Fear of bodily sensations: -0.3823291810495087, T1 Dysfunctional attitudes: -0.2250808121114963, T1 General psychopathology: Global Severity Index (GSI): 0.5256754297767214, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 3.0, Change in Positive mental health (T2-T1): -0.235399282050399, Change in Social support (T2-T1): -0.2388467390237219, Change in General self-efficacy (T2-T1): 0.923845632983056, Change in Life satisfaction (T2-T1): 0.1407378746091632, Change in Anxiety sensitivity (T2-T1): -0.4476516961918859, Change in Fear of bodily sensations (T2-T1): 0.0291707000609912, Change in Dysfunctional attitudes (T2-T1): 0.4849021865236002, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -0.2506606365193577, Total mental disorders incidence point prevalence: 1.0'] Based on the previous example data prompts, classify the following data. Does the following person develop a psychological disorder between time point T1 and T2? Data: T1 Positive mental health: -0.0279170753483525, T1 Social support: 1.0790451808002794, T1 General self-efficacy: -2.3549374763869046, T1 Life satisfaction: -0.471818725223128, T1 Stress: 0.0419806820921755, T1 Problem-focused coping: 0.8532782878883876, T1 Emotion-focused coping: -0.8456281474585625, T1 Anxiety sensitivity: 0.5557512543954795, T1 Fear of bodily sensations: 1.241666884265578, T1 Dysfunctional attitudes: -0.2250808121114963, T1 General psychopathology: Global Severity Index (GSI): 1.5062628203345918, Education: 2.0, T1 BMI: 2.0, Socioeconomic status: 2.0, Change in Positive mental health (T2-T1): -0.7520166349788642, Change in Social support (T2-T1): -0.460474567131092, Change in General self-efficacy (T2-T1): 1.7532147220525784, Change in Life satisfaction (T2-T1): 0.3167090300485398, Change in Anxiety sensitivity (T2-T1): 0.5185167790561809, Change in Fear of bodily sensations (T2-T1): 1.781472184716851, Change in Dysfunctional attitudes (T2-T1): 0.8097267435207866, Change in General psychopathology: Global Severity Index (GSI) (T2-T1): -1.09104984935167\n",
      "NO\n",
      "Time taken: 1.0658280849456787 seconds\n",
      "NO    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:38:27.698617Z",
     "start_time": "2025-05-18T15:38:16.344262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vignette_y_pred_grok = []\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ.get(\"XAI_API_KEY\"),\n",
    "    base_url = \"https://api.x.ai/v1\",\n",
    ")\n",
    "\n",
    "# measure time in seconds\n",
    "start = time.time()\n",
    "\n",
    "# iterate over the test set and save the response for each prompt in an array\n",
    "for prompt in X_test_vignette_prompt:\n",
    "    completion = client.chat.completions.create(\n",
    "        model = \"grok-3-beta\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": vignette_instruction},\n",
    "            {\"role\": \"user\", \"content\": X_test_simple_prompt[0]},\n",
    "        ],\n",
    "    )\n",
    "    vignette_y_pred_grok.append(completion.choices[0].message.content)\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")\n",
    "time_grok_vignette = end - start\n",
    "time_grok_vignette_df = pd.DataFrame({\"time\": [time_grok_vignette]})\n",
    "time_grok_vignette_df.to_csv(\"../exp/times_LLMs/Grok/time_grok_vignette_prompt.csv\", sep = \",\", index = False)\n",
    "\n",
    "# value counts for array\n",
    "counts_vignette_grok = pd.Series(vignette_y_pred_grok).value_counts()\n",
    "print(counts_vignette_grok)\n",
    "\n",
    "# convert YES to 1 and NO to 0\n",
    "vignette_y_pred_grok_val = [1 if response == \"YES\" else 0 for response in vignette_y_pred_grok]\n",
    "\n",
    "# save the array to a csv file\n",
    "vignette_df_grok = pd.DataFrame(vignette_y_pred_grok_val, columns = [\"y_pred\"])\n",
    "vignette_df_grok.to_csv(\"../exp/preds_LLMs/Grok/y_pred_grok_vignette_prompt.csv\", sep = \",\", index = False)"
   ],
   "id": "fc98053086ee26ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A woman with a BMI of 1.0, an education level of 2.0, and a socioeconomic status of 2.0 has the following psychological profile: At time point 1, she showed average (-0.028) positive mental health, average (0.142) social support, and average (0.365) general self-efficacy. Her life satisfaction was average (0.337), and she relied on above average (1.732) problem-focused and average (0.208) emotion-focused coping strategies. Anxiety sensitivity was average (0.159), and her fear of bodily sensations was average (0.286). She reported average (0.275) levels of dysfunctional attitudes and average (0.017) levels of general psychopathology. Her stress level was average (0.442). By time point 2, approximately 17 months later, she reported similar (-0.752) positive mental health, similar (0.706) social support, and similar (-0.182) self-efficacy. Life satisfaction was similar (0.141). Anxiety sensitivity was reported to be similar (-0.862), and fear of bodily sensations was similar (-0.847). Dysfunctional attitudes were similar (0.485), and general psychopathology was similar (-0.826) compared to time point 1. Does this person develop a psychological disorder between time point T1 and T2?\n",
      "NO\n",
      "A woman with a BMI of 2.0, an education level of 2.0, and a socioeconomic status of 2.0 has the following psychological profile: At time point 1, she showed average (-0.028) positive mental health, above average (1.079) social support, and below average (-2.355) general self-efficacy. Her life satisfaction was average (-0.472), and she relied on average (0.853) problem-focused and average (-0.846) emotion-focused coping strategies. Anxiety sensitivity was average (0.556), and her fear of bodily sensations was above average (1.242). She reported average (-0.225) levels of dysfunctional attitudes and above average (1.506) levels of general psychopathology. Her stress level was average (0.042). By time point 2, approximately 17 months later, she reported similar (-0.752) positive mental health, similar (-0.460) social support, and increased (1.753) self-efficacy. Life satisfaction was similar (0.317). Anxiety sensitivity was reported to be similar (0.519), and fear of bodily sensations was increased (1.781). Dysfunctional attitudes were similar (0.810), and general psychopathology was decreased (-1.091) compared to time point 1. Does this person develop a psychological disorder between time point T1 and T2?\n",
      "NO\n",
      "Time taken: 11.324376106262207 seconds\n",
      "NO    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b65a368b0299d5ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.8 Mistral",
   "id": "56ed79ae4b6367e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7443857e89b1d96f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
