# Forecasting Psychological Disorders with LLMs and Machine Learning

This repo contains the code and data used for my master thesis "Forecasting Psychological Disorders with Large Language Models and Machine Learning", supervised by the Methods Center at the University of TÃ¼bingen and XXX.

This thesis evaluated ML algorithms, LLMs, and unification approaches for forecasting psychological disorder incidence between two time points, using an exemplary longitudinal psychological dataset.

**RQ1**: How does the performance of traditional ML models and classification through LLMs and prompts compare in forecasting the binary incidence of psychological disorders?

**RQ2**: How do unification approaches of ML and LLMs perform in forecasting the binary incidence of psychological disorders?

**RQ3**: Can ad hoc explanations generated by LLMs for misclassified cases improve the interpretability of predictions of psychological disorders and categorize reasons for failure?

---

## Structure

You will find the experiments I conducted in `.\exp`, the data I used (Dresden Predictor Study (DPS), a study about predictors of psychological disorders by Trumpf, Margraf, Vriends, Meyer, & Becker, 2010) and the prompts I build in the directory `.\dat`, and the report and figures in `.\doc`.

---

## Methods

I compared **six ML models**, including linear, neural, probabilistic, tree-based, kernel-based and distance-based models, **six prompting strategies** across **six state-of-the-art LLMs** and **three unification approaches** combining ML and LLM strengths.

<p align>
  <img src = "doc/figs/00_methods/table_methods.png" height = "600">
</p>

---

## Results

All experiments can be found in `.\exp`. `01_ML` contains all implemented ML models and their predictions, `02_LLM` contains the creation of prompts, all implemented LLM APIs, and their predictions, `03_Unification` contains the unification approaches, and `04_Reasons_Misclassifications` contains the prompting for reasons of misclassifications. 



---

## Main Literature
